# ===================================================================
#             ЕДИНЫЙ ФАЙЛ КОНФИГУРАЦИИ ДЛЯ AI-REASONING-LAB
# ===================================================================

# --- ЭТАП 1: ПОДГОТОВКА МОДЕЛЕЙ (для скрипта create_model.py) ---
# Сначала запустите `python scripts/create_model.py`, чтобы скачать
# и создать указанные ниже модели в Ollama.

# --- Модель №0 для слабых ПК ---
PREPARE_MODEL_0_ENABLED="true"
PREPARE_MODEL_0_NAME="jan-long-q4" # Это имя мы будем использовать в тестах ниже
PREPARE_MODEL_0_GGUF_URL="https://huggingface.co/janhq/jan-v1-4b-GGUF/resolve/main/jan-v1-4b.Q4_K_M.gguf"
PREPARE_MODEL_0_PARAMS_NUM_CTX="262144"
PREPARE_MODEL_0_PARAMS_TEMPERATURE="0.1"
PREPARE_MODEL_0_SYSTEM_PROMPT="Ты — точный и педантичный ассистент по извлечению информации..."

# --- Модель №1 для мощных ПК (Windows/Linux) ---
PREPARE_MODEL_1_ENABLED="true"
PREPARE_MODEL_1_NAME="jan-long-q8" # Это имя мы будем использовать в тестах ниже
PREPARE_MODEL_1_GGUF_URL="https://huggingface.co/janhq/jan-v1-4b-GGUF/resolve/main/jan-v1-4b.Q8_0.gguf"
PREPARE_MODEL_1_PARAMS_NUM_CTX="262144"
PREPARE_MODEL_1_PARAMS_TEMPERATURE="0.1"
PREPARE_MODEL_1_SYSTEM_PROMPT="Ты — точный и педантичный ассистент по извлечению информации..."


# ===================================================================
#          ЭТАП 2: ТЕСТИРОВАНИЕ (для run_baselogic_benchmark.py)
# ===================================================================
# Этот раздел использует модели, подготовленные на ЭТАПЕ 1.

# --- Общие параметры тестирования ---
BC_RUNS_PER_TEST=1 # Для стресс-теста достаточно 1 запуска на категорию

# --- Набор тестов для запуска ---
BC_TESTS_TO_RUN=t_context_stress
# Все текущие тесты t01_simple_logic, t02_instructions, t03_code_gen, t04_data_extraction, t05_summarization, t06_mathematics, custom_logic, t_context_stress

# --- Настройки логирования ---
BC_LOGGING_LEVEL="INFO"
BC_LOGGING_FORMAT="DETAILED"
BC_LOGGING_DIRECTORY="logs"

# --- Список моделей для тестирования ---
# Мы используем имена, которые задали на ЭТАПЕ 1.

# --- Модель №0 ---
BC_MODELS_0_NAME="jan-long-q4"
BC_MODELS_0_CLIENT_TYPE="ollama"
# Здесь не нужно указывать параметры, так как они уже "зашиты" в модель
# при ее создании на ЭТАПЕ 1. Но можно переопределить, если нужно.
BC_MODELS_0_OPTIONS_QUERY_TIMEOUT="600" # 10 минут
BC_MODELS_0_PROMPTING_SYSTEM_PROMPT="Ты — точный и педантичный ассистент..."
BC_MODELS_0_GENERATION_TEMPERATURE="0.1"
BC_MODELS_0_INFERENCE_NUM_CTX="1024"
BC_MODELS_0_INFERENCE_STREAM="false"
BC_MODELS_0_INFERENCE_THINK="true"
BC_MODELS_0_GENERATION_MAX_TOKENS="512"  # Ограничиваем длину ответа
BC_MODELS_0_GENERATION_STOP='["**Ответ**", "\n\n"]'  # Стоп-токены для завершения
BC_MODELS_0_STREAM_MAX_CHUNKS="2000"

# --- Модель №1 ---
BC_MODELS_1_NAME="jan-long-q8"
BC_MODELS_1_CLIENT_TYPE="ollama"
BC_MODELS_1_OPTIONS_QUERY_TIMEOUT="600" # 10 минут
BC_MODELS_1_PROMPTING_SYSTEM_PROMPT="Ты — точный и педантичный ассистент..."
BC_MODELS_1_GENERATION_TEMPERATURE="0.1"
BC_MODELS_1_INFERENCE_STREAM="false"
BC_MODELS_1_INFERENCE_THINK="true"


# --- Стресс-тест контекста (для плагина t_context_stress) ---
CST_CONTEXT_LENGTHS_K="8,16,32,64,128,256,512,1024"
CST_NEEDLE_DEPTH_PERCENTAGES="10,50,90"
