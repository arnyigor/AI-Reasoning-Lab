# ===================================================================
#  Файл конфигурации для тестовой платформы "Базовый Контроль"
#  Все настройки задаются через переменные окружения.
# ===================================================================
# Скопируйте этот файл в .env и измените значения по необходимости.

# --- Общие параметры тестирования ---
BC_RUNS_PER_TEST=10

# --- Набор тестов для запуска (через запятую) ---
BC_TESTS_TO_RUN=t02_instructions,t05_summarization

# --- Настройки логирования ---
BC_LOGGING_LEVEL="INFO"        # DEBUG, INFO, WARNING, ERROR, CRITICAL
BC_LOGGING_FORMAT="DETAILED"   # SIMPLE, DETAILED, JSON
BC_LOGGING_DIRECTORY="logs"    # Директория для логов

# --- Список моделей и их индивидуальные настройки ---
# Каждая модель определяется блоком переменных с уникальным индексом (BC_MODELS_0_*, BC_MODELS_1_*, etc.)

# --- Модель №0: Запуск через LM Studio (или другой OpenAI-совместимый сервер) ---
BC_MODELS_0_NAME="Meta-Llama-3-8B-Instruct-GGUF"
BC_MODELS_0_CLIENT_TYPE="openai_compatible" # openai_compatible, ollama
BC_MODELS_0_API_BASE="http://localhost:1234/v1"
BC_MODELS_0_API_KEY="lm-studio"
# Вложенные опции задаются через подчеркивание
BC_MODELS_0_OPTIONS_GENERATION_TEMPERATURE="0.7"
BC_MODELS_0_OPTIONS_GENERATION_MAX_TOKENS="1024"
# BC_MODELS_0_OPTIONS_GENERATION_STOP="<|eot_id|>" # Для одного стоп-токена
BC_MODELS_0_OPTIONS_PROMPTING_SYSTEM_PROMPT="You are a precise and helpful assistant. Provide clear and direct answers."
BC_MODELS_0_OPTIONS_QUERY_TIMEOUT="60"

# В чате Ollama:
/set parameter temperature 0.6
/set parameter top_p 0.95
/set parameter num_ctx 8192


# --- Модель №1: Запуск через Ollama ---
BC_MODELS_1_NAME="jan-v1-4b"
BC_MODELS_1_CLIENT_TYPE="ollama"
BC_MODELS_1_OPTIONS_GENERATION_TEMPERATURE="0.6"
BC_MODELS_1_OPTIONS_QUERY_TIMEOUT="180"


# --- Модель №2: Еще один пример для OpenAI-совместимого сервера ---
# BC_MODELS_2_NAME="tngtech/deepseek-r1t-chimera:free"
# BC_MODELS_2_CLIENT_TYPE="openai_compatible"
# BC_MODELS_2_API_BASE="http://127.0.0.1:1337/v1"
# BC_MODELS_2_API_KEY="not-needed"
# BC_MODELS_2_OPTIONS_GENERATION_TEMPERATURE="0.5"
# BC_MODELS_2_OPTIONS_PROMPTING_SYSTEM_PROMPT=""


GGUF_MODEL_PATH=path.gguf # Полный путь к GGUF