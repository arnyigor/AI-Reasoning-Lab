# ===================================================================
#             ЕДИНЫЙ ФАЙЛ КОНФИГУРАЦИИ ДЛЯ AI-REASONING-LAB
# ===================================================================

# --- ЭТАП 1: ПОДГОТОВКА МОДЕЛЕЙ (для скрипта create_model.py) ---
# Сначала запустите `python scripts/create_model.py`, чтобы скачать
# и создать указанные ниже модели в Ollama.

# --- Модель №0 для слабых ПК ---
PREPARE_MODEL_0_ENABLED="true"
PREPARE_MODEL_0_NAME="jan-long-q4" # Это имя мы будем использовать в тестах ниже
PREPARE_MODEL_0_GGUF_URL="https://huggingface.co/janhq/jan-v1-4b-GGUF/resolve/main/jan-v1-4b.Q4_K_M.gguf"
PREPARE_MODEL_0_PARAMS_NUM_CTX="262144"
PREPARE_MODEL_0_PARAMS_TEMPERATURE="0.1"
PREPARE_MODEL_0_SYSTEM_PROMPT="Ты — точный и педантичный ассистент по извлечению информации..."

# --- Модель №1 для мощных ПК (Windows/Linux) ---
PREPARE_MODEL_1_ENABLED="true"
PREPARE_MODEL_1_NAME="jan-long-q8" # Это имя мы будем использовать в тестах ниже
PREPARE_MODEL_1_GGUF_URL="https://huggingface.co/janhq/jan-v1-4b-GGUF/resolve/main/jan-v1-4b.Q8_0.gguf"
PREPARE_MODEL_1_PARAMS_NUM_CTX="262144"
PREPARE_MODEL_1_PARAMS_TEMPERATURE="0.1"
PREPARE_MODEL_1_SYSTEM_PROMPT="Ты — точный и педантичный ассистент по извлечению информации..."

GEMINI_API_KEY=""
# ===================================================================
#          ЭТАП 2: ТЕСТИРОВАНИЕ (для run_baselogic_benchmark.py)
# ===================================================================
# Этот раздел использует модели, подготовленные на ЭТАПЕ 1.

# --- Общие параметры тестирования ---
BC_RUNS_PER_TEST=1 # Для стресс-теста достаточно 1 запуска на категорию

# --- Набор тестов для запуска ---
BC_TESTS_TO_RUN=t_context_stress
# Все текущие тесты t01_simple_logic, t02_instructions, t03_code_gen, t04_data_extraction, t05_summarization, t06_mathematics, custom_logic, t_context_stress

# --- Настройки логирования ---
BC_LOGGING_LEVEL="INFO"
BC_LOGGING_FORMAT="DETAILED"
BC_LOGGING_DIRECTORY="logs"

# --- Список моделей для тестирования ---
# --- Модель №0 ---
BC_MODELS_0_NAME="jan-long-q4"
BC_MODELS_0_CLIENT_TYPE="openai_compatible"
BC_MODELS_0_API_BASE="http://127.0.0.1:1234/v1" # ИЗМЕНИТЕ НА СВОЙ ПОРТ (11434-Ollama, 1234-LM Studio, 1337-Jan и т.д.)

# Общие опции, которые читает TestRunner/Adapter
BC_MODELS_0_OPTIONS_QUERY_TIMEOUT="600" # Таймаут на весь запрос
BC_MODELS_0_INFERENCE_STREAM="false"    # Включить/выключить потоковый режим
BC_MODELS_0_INFERENCE_THINK="true"      # Включить/выключить режим chain_of_thought <think>

# Опции, которые передаются напрямую в API модели
BC_MODELS_0_PROMPTING_SYSTEM_PROMPT="Ты — точный и педантичный ассистент..."
BC_MODELS_0_GENERATION_TEMPERATURE="0.1"
BC_MODELS_0_GENERATION_MAX_TOKENS="512"
# Опционально: используйте стоп-токены, если уверены, что сервер их поддерживает
# BC_MODELS_0_GENERATION_STOP="<|im_end|>" # Пример одного стоп-токена в виде строки

# --- Стресс-тест контекста (для плагина t_context_stress) ---
CST_CONTEXT_LENGTHS_K="8,16,32,64,128,256,512,1024"
CST_NEEDLE_DEPTH_PERCENTAGES="10,50,90"
