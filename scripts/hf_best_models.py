import json
import re
from datetime import datetime

from huggingface_hub import HfApi


class GGUFModelRanker:
    def __init__(self):
        self.api = HfApi()

    # ------------------------------------------------------------------
    #   –ü–∞—Ä—Å–µ—Ä –¥–ª—è general.size_label
    # ------------------------------------------------------------------
    _SIZE_LABEL_RE = re.compile(
        r'(?P<main>\d+(?:\.\d+)?)\s*[xX]\s*'
        r'(?P<second>\d+(?:\.\d+)?)(?P<unit>[BbMm])?',  # unit optional
        re.IGNORECASE
    )

    def _parse_size_label(self, label: str) -> float | None:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ ¬´–æ—Å–Ω–æ–≤–Ω–æ–≥–æ¬ª –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ '256x20B'.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å–ª–æ –≤ –º–∏–ª–ª–∏–∞—Ä–¥–∞—Ö (–µ—Å–ª–∏ –ø–µ—Ä–≤—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∑–∞–¥–∞–Ω –≤ –º–∏–ª–ª–∏–æ–Ω–∞—Ö).
        –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞—ë—Ç—Å—è ‚Äì –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è None.
        """
        m = self._SIZE_LABEL_RE.search(label)
        if not m:
            return None

        main_val = float(m.group('main'))          # –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ
        unit     = m.group('unit')                # –º–æ–∂–µ—Ç –±—ã—Ç—å B/M/None

        # –ï—Å–ª–∏ –≤—Ç–æ—Ä–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω –≤ –º–∏–ª–ª–∏–∞—Ä–¥–∞—Ö (20B), —Ç–æ –ø–µ—Ä–≤—ã–π
        # –æ–±—ã—á–Ω–æ –≤ –º–∏–ª–ª–∏–æ–Ω–∞—Ö. –ü–µ—Ä–µ–≤–µ–¥—ë–º –µ–≥–æ –≤ –º–∏–ª–ª–∏–∞—Ä–¥—ã.
        if unit == 'b':
            return main_val / 1000.0              # 256M ‚Üí 0,256B

        # –ò–Ω–∞—á–µ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —á–∏—Å–ª–æ —É–∂–µ –≤ –º–∏–ª–ª–∏–∞—Ä–¥–∞—Ö (–∏–ª–∏ –±–µ–∑ —É—Ç–æ—á–Ω–µ–Ω–∏—è)
        return main_val

    # ------------------------------------------------------------------
    #   –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    # ------------------------------------------------------------------
    def extract_parameters(self, model_info):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏, —Ç–µ–≥–æ–≤ –∏–ª–∏ size_label."""
        # 1) –ü–æ–ø—ã—Ç–∫–∞ –≤–∑—è—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ general.size_label (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
        if hasattr(model_info, 'general') and getattr(model_info.general, 'size_label', None):
            label = model_info.general.size_label
            params_from_label = self._parse_size_label(label)
            if params_from_label is not None:
                return params_from_label

        # 2) –û–±—ã—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã ‚Äì –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ / —Ç–µ–≥–∏ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        name = getattr(model_info, 'modelId', '').lower()
        param_patterns = [
            r'(\d+\.?\d*)\s*[bm]b',
            r'(\d+\.?\d*)b',
            r'(\d+)\s*billi',
            r'(\d+)\s*m',
        ]

        for pattern in param_patterns:
            match = re.search(pattern, name)
            if match:
                value = float(match.group(1))
                if 'm' in name or 'million' in name:
                    return value / 1000.0
                return value

        if hasattr(model_info, 'tags'):
            for tag in model_info.tags:
                tag = tag.lower()
                for pattern in param_patterns:
                    match = re.search(pattern, tag)
                    if match:
                        value = float(match.group(1))
                        if 'm' in tag or 'million' in tag:
                            return value / 1000.0
                        return value

        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ ‚Äì –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
        return None

    def calculate_score(self, model, weights=(0.5, 0.3, 0.2)):
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ:
            - downloads (50%)
            - likes     (30%)
            - recency   (20%)

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        ----------
        model   : –æ–±—ä–µ–∫—Ç –∏–∑ HfApi.list_models()
        weights : –∫–æ—Ä—Ç–µ–∂ (download_weight, like_weight, recency_weight)
        """
        # 1. –°—á–∏—Ç–∞–µ–º ‚Äúraw‚Äù‚Äë–∑–Ω–∞—á–µ–Ω–∏—è
        download_score = getattr(model, 'downloads', 0) or 0
        like_score = getattr(model, 'likes', 0) or 0

        # 2. –ù–æ–≤–∏–∑–Ω–∞: 1 –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 7‚ÄØ–¥–Ω–µ–π ‚Üí 0 –ø—Ä–∏ 180+ –¥–Ω—è—Ö
        if hasattr(model, 'createdAt') and model.createdAt:
            try:
                created_date = datetime.fromisoformat(
                    model.createdAt.replace('Z', '+00:00')
                )
                days_old = (datetime.now(created_date.tzinfo) - created_date).days
                recency_score = max(0.0, 1.0 - (days_old / 180))
            except Exception:
                # –ï—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ–ø–æ–Ω—è—Ç–Ω–∞ ‚Äì —Å—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω—é—é –Ω–æ–≤–∏–∑–Ω—É
                recency_score = 0.5
        else:
            recency_score = 0.5

        # 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–∫–∞—á–∏–≤–∞–Ω–∏–π –∏ –ª–∞–π–∫–æ–≤ (–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–π –º–∞—Å—à—Ç–∞–±)
        MAX_DOWNLOADS = 10_000_000  # –ø—Ä–µ–¥–µ–ª –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        MAX_LIKES = 10_000

        norm_download = min(
            1.0, (download_score / MAX_DOWNLOADS) ** 0.5
        )
        norm_like = min(
            1.0, (like_score / MAX_LIKES) ** 0.7
        )

        # 4. –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–π—Ç–∏–Ω–≥
        score = (
                weights[0] * norm_download +
                weights[1] * norm_like +
                weights[2] * recency_score
        )
        return float(score)

    def get_top_gguf_models(self,
                            pipeline_filter=None,
                            min_params=None,
                            max_params=None,
                            min_downloads=0,
                            top_n=50,
                            sort_by='combined'):
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Ç–æ–ø GGUF –º–æ–¥–µ–ª–µ–π —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π

        Args:
            pipeline_filter (str): –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏ ('text-generation', 'text-to-image', –∏ —Ç.–¥.)
            min_params (float): –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–∏–ª–ª–∏–∞—Ä–¥–∞—Ö
            max_params (float): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–∏–ª–ª–∏–∞—Ä–¥–∞—Ö
            min_downloads (int): –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏–π
            top_n (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
            sort_by (str): –ú–µ—Ç–æ–¥ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ ('downloads', 'likes', 'newest', 'combined')
        """
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ GGUF –º–æ–¥–µ–ª–∏
        print("–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ GGUF –º–æ–¥–µ–ª–µ–π —Å Hugging Face...")
        all_models = list(self.api.list_models(
            filter="gguf",
            limit=1000  # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        ))

        print(f"–ù–∞–π–¥–µ–Ω–æ {len(all_models)} GGUF –º–æ–¥–µ–ª–µ–π. –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã...")

        filtered_models = []
        for model in all_models:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏
            if getattr(model, 'private', True):
                continue

            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–∫–∞—á–∏–≤–∞–Ω–∏–π
            downloads = getattr(model, 'downloads', 0) or 0
            if downloads < min_downloads:
                continue

            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏
            if pipeline_filter:
                model_pipeline = getattr(model, 'pipeline_tag', '')
                if not model_pipeline or pipeline_filter.lower() not in model_pipeline.lower():
                    continue

            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
            params = self.extract_parameters(model)
            if params is not None:
                if min_params is not None and params < min_params:
                    continue
                if max_params is not None and params > max_params:
                    continue

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –≤ –º–æ–¥–µ–ª—å
            model.parameters = params
            filtered_models.append(model)

        print(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å {len(filtered_models)} –º–æ–¥–µ–ª–µ–π")

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π
        if sort_by == 'downloads':
            sorted_models = sorted(filtered_models, key=lambda x: getattr(x, 'downloads', 0) or 0, reverse=True)
        elif sort_by == 'likes':
            sorted_models = sorted(filtered_models, key=lambda x: getattr(x, 'likes', 0) or 0, reverse=True)
        elif sort_by == 'newest':
            sorted_models = sorted(filtered_models,
                                   key=lambda x: getattr(x, 'createdAt', '') or '',
                                   reverse=True)
        else:  # combined
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            for model in filtered_models:
                model.combined_score = self.calculate_score(model)
            sorted_models = sorted(filtered_models, key=lambda x: x.combined_score, reverse=True)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π
        top_models = sorted_models[:top_n]

        return top_models

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  format_model_info  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def format_model_info(self, model):
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—ã–≤–æ–¥–∞"""
        model_id = getattr(model, 'modelId', 'N/A')
        downloads = getattr(model, 'downloads', 'N/A')
        likes = getattr(model, 'likes', 'N/A')
        pipeline = getattr(model, 'pipeline_tag', 'N/A')
        params = getattr(model, 'parameters', 'N/A')
        created = getattr(model, 'createdAt', 'N/A')

        if pipeline == 'text-generation':
            pipeline_pretty = 'üî§ Text Generation'
        elif pipeline == 'text-to-image':
            pipeline_pretty = 'üñºÔ∏è Text-to-Image'
        elif pipeline == 'image-text-to-text':
            pipeline_pretty = 'üì∏ Image-to-Text'
        elif pipeline == 'automatic-speech-recognition':
            pipeline_pretty = 'üé§ Speech Recognition'
        elif pipeline == 'text-to-speech':
            pipeline_pretty = 'üó£Ô∏è Text-to-Speech'
        else:
            pipeline_pretty = f'üîß {pipeline}'

        param_str = f"{params:.1f}B" if isinstance(params, (int, float)) else "N/A"
        url = f"https://huggingface.co/{model_id}"  # ‚Üê¬†–Ω–æ–≤—ã–π –∞—Ç—Ä–∏–±—É—Ç

        return {
            'name': model_id,
            'parameters': param_str,
            'pipeline': pipeline_pretty,
            'downloads': downloads,
            'likes': likes,
            'created': created.split('T')[0] if created != 'N/A' else 'N/A',
            'url': url,  # ‚Üê¬†–≤–æ–∑–≤—Ä–∞—â–∞–µ–º
            'score': round(getattr(model, 'combined_score', 0), 3) if hasattr(
                model, 'combined_score') else 'N/A'
        }

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  print_top_models  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def print_top_models(self, models):
        """–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–ø –º–æ–¥–µ–ª—è—Ö"""
        # ----- HEADER --------------------------------------------------------------
        print("\n" + "=" * 100)
        print(f"{'üèÜ –¢–û–ü-50 –õ–£–ß–®–ò–• GGUF –ú–û–î–ï–õ–ï–ô':^100}")
        print("=" * 100)

        # ----- TABLE HEADERS ------------------------------------------------------
        header = (
            f"{'#':^3} | {'–ú–û–î–ï–õ–¨ (URL)':^120} | {'–¢–ò–ü –ó–ê–î–ê–ß–ò':^20} | "
            f"{'–ü–ê–†–ê–ú–ï–¢–†–´':^10} | {'–°–ö–ê–ß–ò–í–ê–ù–ò–ô':^10} | {'–õ–ê–ô–ö–û–í':^6}"
        )
        print(header)
        print("-" * len(header))

        # ----- ROWS ---------------------------------------------------------------
        for i, model in enumerate(models, 1):
            info = self.format_model_info(model)

            # –í—Å—Ç–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É —Ä—è–¥–æ–º —Å –∏–º–µ–Ω–µ–º –º–æ–¥–µ–ª–∏
            name_with_link = f"{info['name']} ({info['url']})"

            print(
                f"{i:^3} | {name_with_link[:120]:<120} | {info['pipeline'][:20]:<20} | "
                f"{info['parameters']:^10} | {info['downloads']:^10} | {info['likes']:^6}"
            )

        # ----- FOOTER -------------------------------------------------------------
        print("=" * 100)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    ranker = GGUFModelRanker()

    # –¢–æ–ø‚Äë50 –ª—É—á—à–∏—Ö GGUF –º–æ–¥–µ–ª–µ–π (–∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞)
    print("–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–ø-50 –ª—É—á—à–∏—Ö GGUF –º–æ–¥–µ–ª–µ–π...")
    top_models = ranker.get_top_gguf_models(
        top_n=50,
        sort_by='combined',
        min_downloads=100
    )
    ranker.print_top_models(top_models)

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
    print("\n" + "=" * 100)
    print("–§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û –ö–û–ù–ö–†–ï–¢–ù–´–ú –ö–†–ò–¢–ï–†–ò–Ø–ú")
    print("=" * 100)

    min_params_range = 9.0  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–≤ –º–ª—Ä–¥.)
    max_params_range = 40.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

    text_models = ranker.get_top_gguf_models(
        pipeline_filter="text-generation",
        min_params=min_params_range,
        max_params=max_params_range,
        min_downloads=1000,
        top_n=10,
        sort_by='combined'
    )

    ranker.print_top_models(top_models)

    # –í–∞—Ä–∏–∞–Ω—Ç 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
    print("\n" + "=" * 100)
    print("–§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û –ö–û–ù–ö–†–ï–¢–ù–´–ú –ö–†–ò–¢–ï–†–ò–Ø–ú")
    print("=" * 100)

    # –¢–æ–ø-10 text-generation –º–æ–¥–µ–ª–µ–π
    top_text_models = ranker.get_top_gguf_models(
        pipeline_filter="text-generation",
        min_params=min_params_range,
        max_params=max_params_range,
        min_downloads=1000,
        top_n=10,
        sort_by='combined'
    )

    print(f"\nüî§ –¢–û–ü-10 TEXT GENERATION –ú–û–î–ï–õ–ï–ô ({min_params_range:,}B-{max_params_range:,}B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤):")
    ranker.print_top_models(top_text_models)

    # –¢–æ–ø-10 text-to-image –º–æ–¥–µ–ª–µ–π
    image_models = ranker.get_top_gguf_models(
        pipeline_filter="text-to-image",
        min_downloads=500,
        top_n=10,
        sort_by='combined'
    )

    print("\nüñºÔ∏è –¢–û–ü-10 TEXT-TO-IMAGE –ú–û–î–ï–õ–ï–ô:")
    ranker.print_top_models(image_models)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON
    results = [
        {
            'rank': i,
            'model': ranker.format_model_info(model)
        } for i, model in enumerate(top_models, 1)
    ]

    with open('top_50_gguf_models.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª 'top_50_gguf_models.json'")
