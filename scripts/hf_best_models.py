import hashlib
import json
import math
import os
import re
from datetime import datetime, timezone
from typing import List, Dict, Any

from huggingface_hub import HfApi

# –§–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏
HISTORY_FILE = "gguf_ranking_history.json"


class RankingHistoryManager:
    def __init__(self, filepath=HISTORY_FILE, max_history=20):
        self.filepath = filepath
        self.max_history = max_history
        self.data = self._load_data()

    def _load_data(self):
        if not os.path.exists(self.filepath):
            return {}
        try:
            with open(self.filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {}

    def _save_data(self):
        with open(self.filepath, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)

    def _generate_config_key(self, params: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ö—ç—à –¥–ª—è –Ω–∞–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏."""
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª—é—á–∏, —á—Ç–æ–±—ã –ø–æ—Ä—è–¥–æ–∫ –Ω–µ –≤–ª–∏—è–ª –Ω–∞ —Ö—ç—à
        s = json.dumps(params, sort_keys=True)
        return hashlib.md5(s.encode('utf-8')).hexdigest()

    def process_ranking(self, current_models: List[Any], run_params: Dict[str, Any]):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Ç–æ–ø —Å –∏—Å—Ç–æ—Ä–∏–µ–π, —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–∏–Ω–∞–º–∏–∫—É –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º –∞—Ç—Ä–∏–±—É—Ç–æ–º .rank_delta
        """
        config_key = self._generate_config_key(run_params)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è —ç—Ç–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if config_key not in self.data:
            self.data[config_key] = {
                "params": run_params,
                "snapshots": []
            }

        history_entry = self.data[config_key]
        snapshots = history_entry["snapshots"]

        # 1. –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—É—â–∏–π "—Å–ª–µ–ø–æ–∫" (—Ç–æ–ª—å–∫–æ ID –∏ —Ä–∞–Ω–≥ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
        current_snapshot_map = {
            getattr(m, 'id'): idx
            for idx, m in enumerate(current_models, 1)
        }
        current_ids_ordered = [getattr(m, 'id') for m in current_models]

        # 2. –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–µ–ø–æ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        last_snapshot_map = {}
        last_ids_ordered = []

        if snapshots:
            last_record = snapshots[-1]
            # last_record['items'] - —ç—Ç–æ —Å–ø–∏—Å–æ–∫ dict {'id': ..., 'rank': ...}
            last_snapshot_map = {item['id']: item['rank'] for item in last_record['items']}
            last_ids_ordered = [item['id'] for item in last_record['items']]

        # 3. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–∏–Ω–∞–º–∏–∫—É –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        for idx, model in enumerate(current_models, 1):
            mid = getattr(model, 'id')
            if not snapshots:
                # –ò—Å—Ç–æ—Ä–∏–∏ –Ω–µ—Ç –≤–æ–æ–±—â–µ -> –≤—Å–µ –Ω–æ–≤—ã–µ
                model.rank_delta = "new"
                model.prev_rank = None
            elif mid not in last_snapshot_map:
                # –í –ø—Ä–æ—à–ª–æ–º —Ç–æ–ø–µ –Ω–µ –±—ã–ª–æ -> New
                model.rank_delta = "new"
                model.prev_rank = None
            else:
                prev_rank = last_snapshot_map[mid]
                diff = prev_rank - idx  # –ï—Å–ª–∏ –±—ã–ª 5, —Å—Ç–∞–ª 3: 5-3 = +2 (—Ä–æ—Å—Ç)
                model.rank_delta = diff
                model.prev_rank = prev_rank

        # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ –ø–æ—Ä—è–¥–æ–∫ –∏–ª–∏ —Å–æ—Å—Ç–∞–≤ —Ç–æ–ø–∞
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å–ø–∏—Å–∫–∏ ID. –ï—Å–ª–∏ –æ–Ω–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã - –Ω–∏—á–µ–≥–æ –Ω–µ –ø–∏—à–µ–º (—ç–∫–æ–Ω–æ–º–∏–º –º–µ—Å—Ç–æ)
        has_changed = (current_ids_ordered != last_ids_ordered)

        if has_changed:
            print(f"üìù –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ. –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –≤ –∏—Å—Ç–æ—Ä–∏—é (Config: {config_key[:8]})...")

            new_record = {
                "timestamp": datetime.now().isoformat(),
                "items": [
                    {
                        "id": getattr(m, 'id'),
                        "rank": idx,
                        "score": getattr(m, 'combined_score', 0)
                    }
                    for idx, m in enumerate(current_models, 1)
                ]
            }

            snapshots.append(new_record)

            # –†–æ—Ç–∞—Ü–∏—è (—É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ, –µ—Å–ª–∏ –±–æ–ª—å—à–µ –ª–∏–º–∏—Ç–∞)
            if len(snapshots) > self.max_history:
                snapshots.pop(0)  # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π

            self._save_data()
        else:
            print("üí§ –†–µ–π—Ç–∏–Ω–≥ –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—É—Å–∫–∞. –ò—Å—Ç–æ—Ä–∏—è –Ω–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∞.")

        return current_models


class GGUFModelRanker:
    def __init__(self):
        self.api = HfApi()
        self.history_manager = RankingHistoryManager()  # –ü–æ–¥–∫–ª—é—á–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏

        self._SIZE_LABEL_RE = re.compile(
            r'(?P<main>\d+(?:\.\d+)?)\s*[xX]?\s*(?P<second>\d+(?:\.\d+)?)(?P<unit>[BbMm])?',
            re.IGNORECASE
        )

    # --- (–ú–µ—Ç–æ–¥—ã –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ extract_parameters —Ç–µ –∂–µ, —Å–æ–∫—Ä–∞—â–µ–Ω—ã –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏) ---
    def _parse_size_label(self, label: str) -> float | None:
        if not label: return None
        m = self._SIZE_LABEL_RE.search(label)
        if not m: return None
        main_val = float(m.group('main'))
        unit = m.group('unit')
        if 'x' in label.lower() and m.group('second'):
            main_val = main_val * float(m.group('second'))
        if unit and unit.lower() == 'm': return main_val / 1000.0
        return main_val

    def extract_parameters(self, model_info) -> float | None:
        if hasattr(model_info, 'general') and getattr(model_info.general, 'size_label', None):
            val = self._parse_size_label(model_info.general.size_label)
            if val: return val
        name = getattr(model_info, 'id', '').lower()
        patterns = [r'(\d+(?:\.\d+)?)x(\d+(?:\.\d+)?)b', r'(\d+(?:\.\d+)?)[b]']
        for p in patterns:
            match = re.search(p, name)
            if match:
                vals = match.groups()
                if len(vals) == 2: return float(vals[0]) * float(vals[1])
                return float(vals[0])
        return None

    def calculate_score(self, model, weights=(0.25, 0.45, 0.30)):
        downloads = getattr(model, 'downloads', 0) or 0
        likes = getattr(model, 'likes', 0) or 0

        # 1. –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è (Power Law distribution)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–∏–µ –¥–µ–ª–∏—Ç–µ–ª–∏, —Ç–∞–∫ –∫–∞–∫ GGUF —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –∏–º–µ—é—Ç –º–µ–Ω—å—à–µ —Ç—Ä–∞—Ñ–∏–∫–∞, —á–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—ã
        log_downloads = math.log10(downloads + 1)
        log_likes = math.log10(likes + 1)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è:
        # 6.0 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç 1 –º–ª–Ω —Å–∫–∞—á–∏–≤–∞–Ω–∏–π (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è GGUF)
        # 4.0 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç 10,000 –ª–∞–π–∫–æ–≤ (—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –ø–æ—Ç–æ–ª–æ–∫ –¥–ª—è —Ç–æ–ø–æ–≤ –≤—Ä–æ–¥–µ TheBloke)
        norm_download = min(1.0, log_downloads / 6.0)
        norm_like = min(1.0, log_likes / 4.0)

        # 2. –£–º–Ω–∞—è —Å–≤–µ–∂–µ—Å—Ç—å (Sigmoid –≤–º–µ—Å—Ç–æ Linear)
        # –ü–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª—è–º "–∂–∏—Ç—å" —á—É—Ç—å –¥–æ–ª—å—à–µ, –Ω–æ —Ä–µ–∑–∫–æ —à—Ç—Ä–∞—Ñ—É–µ—Ç —Å–æ–≤—Å–µ–º —Å—Ç–∞—Ä—å–µ
        created_at = getattr(model, 'created_at', None)
        recency_score = 0.0
        if created_at:
            if isinstance(created_at, str):
                created_at = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
            if created_at.tzinfo is None: created_at = created_at.replace(tzinfo=timezone.utc)

            delta_days = (datetime.now(timezone.utc) - created_at).days

            # "–ü–ª–∞—Ç–æ" –Ω–æ–≤–∏–∑–Ω—ã: –ø–µ—Ä–≤—ã–µ 30 –¥–Ω–µ–π –º–æ–¥–µ–ª—å —Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–æ–≤–æ–π (1.0)
            if delta_days < 30:
                recency_score = 1.0
            else:
                # –ú—è–≥–∫–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ –¥–æ 0 –∑–∞ –≥–æ–¥ (365 –¥–Ω–µ–π), –∞ –Ω–µ –∑–∞ –ø–æ–ª–≥–æ–¥–∞
                recency_score = max(0.0, 1.0 - ((delta_days - 30) / 335.0))

        # 3. –ë–æ–Ω—É—Å –∑–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –õ–∞–π–∫–∏/–°–∫–∞—á–∏–≤–∞–Ω–∏—è (Engagement Rate)
        # –≠—Ç–æ "—Å–µ–∫—Ä–µ—Ç–Ω—ã–π —Å–æ—É—Å" –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–∫—Ä—ã—Ç—ã—Ö –∂–µ–º—á—É–∂–∏–Ω
        engagement_bonus = 0.0
        if downloads > 1000:
            ratio = likes / downloads
            # –ï—Å–ª–∏ –ª–∞–π–∫–æ–≤ –±–æ–ª—å—à–µ 1% –æ—Ç —Å–∫–∞—á–∏–≤–∞–Ω–∏–π ‚Äî —ç—Ç–æ –æ—á–µ–Ω—å –∫—Ä—É—Ç–æ –¥–ª—è HF
            if ratio > 0.01: engagement_bonus = 0.05

        final_score = (weights[0] * norm_download) + \
                      (weights[1] * norm_like) + \
                      (weights[2] * recency_score) + \
                      engagement_bonus

        return min(1.0, final_score)


    def get_top_gguf_models(self,
                            pipeline_filter="text-generation",
                            min_params=None,
                            max_params=None,
                            min_downloads=50,
                            limit_candidates=2000,
                            top_n=50):

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—É—Å–∫–∞ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
        run_params = {
            "pipeline": pipeline_filter,
            "min_params": min_params,
            "max_params": max_params,
            "top_n": top_n
        }

        print(f"üì° –ó–∞–ø—Ä–æ—Å –∫ API Hugging Face (fetch limit: {limit_candidates})...")
        models_iter = self.api.list_models(filter="gguf", sort="downloads", direction=-1, limit=limit_candidates,
                                           full=True)

        candidates = []
        print("‚öôÔ∏è –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Ä–∞—Å—á–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥–∞...")

        for model in models_iter:
            if getattr(model, 'private', False): continue
            dls = getattr(model, 'downloads', 0) or 0
            if dls < min_downloads: continue

            if pipeline_filter:
                tag = getattr(model, 'pipeline_tag', '')
                if tag and pipeline_filter.lower() not in tag.lower(): continue

            p_val = self.extract_parameters(model)
            if min_params is not None:
                if p_val is None or p_val < min_params: continue
            if max_params is not None:
                if p_val is None or p_val > max_params: continue

            model.parsed_params = p_val
            model.combined_score = self.calculate_score(model)
            candidates.append(model)

        candidates.sort(key=lambda x: x.combined_score, reverse=True)
        top_models = candidates[:top_n]

        # --- –ú–ê–ì–ò–Ø –ò–°–¢–û–†–ò–ò ---
        # –ü–µ—Ä–µ–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤ –º–µ–Ω–µ–¥–∂–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –¥–∏–Ω–∞–º–∏–∫–∏
        top_models = self.history_manager.process_ranking(top_models, run_params)

        return top_models

    def print_top_models(self, models):
        print("\n" + "=" * 165)
        print(f"{'üèÜ –¢–û–ü GGUF –ú–û–î–ï–õ–ï–ô –° –î–ò–ù–ê–ú–ò–ö–û–ô':^165}")
        print("=" * 165)

        # –î–æ–±–∞–≤–∏–ª –∫–æ–ª–æ–Ω–∫—É Œî (Delta)
        h = f"{'#':^3} | {'Œî':^6} | {'MODEL ID':<70} | {'PARAMS':^8} | {'DLs':^9} | {'LIKES':^7} | {'CREATED':^12} | {'UPDATED':^12} | {'SCORE':^6}"
        print(h)
        print("-" * 165)

        for i, m in enumerate(models, 1):
            name = getattr(m, 'id', 'N/A')
            if len(name) > 50: name = name[:47] + "..."

            p_str = f"{m.parsed_params:.1f}B" if getattr(m, 'parsed_params', None) else "?"

            dls = getattr(m, 'downloads', 0)
            if dls > 1000000:
                dls_str = f"{dls / 1000000:.1f}M"
            elif dls > 1000:
                dls_str = f"{dls / 1000:.1f}k"
            else:
                dls_str = str(dls)

            created_at = getattr(m, 'created_at', None)
            created_str = str(created_at).split(' ')[0] if created_at else "N/A"

            updated_at = getattr(m, 'lastModified', None)
            updated_str = str(updated_at).split('T')[0] if updated_at else "N/A"

            score = getattr(m, 'combined_score', 0.0)
            likes = getattr(m, 'likes', 0)

            # --- –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –î–∏–Ω–∞–º–∏–∫–∏ ---
            delta = getattr(m, 'rank_delta', 0)
            if delta == "new":
                delta_str = "üÜï"  # New entry
            elif delta == 0:
                delta_str = "‚ûñ"  # No change
            elif delta > 0:
                delta_str = f"üü¢ +{delta}"  # Rose
            else:
                delta_str = f"üî¥ {delta}"  # Fell (delta is negative already)

            print(
                f"{i:^3} | {delta_str:^6} | {name:<70} | {p_str:^8} | {dls_str:>9} | {likes:>7} | {created_str:^12} | {updated_str:^12} | {score:.3f}")
        print("=" * 165)


# ------------------------------------------------------------------
#   –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
# ------------------------------------------------------------------
if __name__ == "__main__":
    ranker = GGUFModelRanker()

    print("\nüîπ –°–¶–ï–ù–ê–†–ò–ô 1: –õ–µ–≥–∫–∏–µ –º–æ–¥–µ–ª–∏ (3B-120B) –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ü–ö")
    top_small = ranker.get_top_gguf_models(
        pipeline_filter="text-generation",
        min_params=8.0,
        max_params=22.0,
        limit_candidates=10000,
        top_n=25
    )
    ranker.print_top_models(top_small)

    print("\nüîπ –°–¶–ï–ù–ê–†–ò–ô 2: –¢—è–∂–µ–ª—ã–µ –º–æ–¥–µ–ª–∏ (120B+) –¥–ª—è —Å–µ—Ä–≤–µ—Ä–æ–≤")
    # –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ: –¥–ª—è —ç—Ç–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –û–¢–î–ï–õ–¨–ù–ê–Ø –∏—Å—Ç–æ—Ä–∏—è,
    # –∏ –æ–Ω–∞ –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏—è 1.
    top_large = ranker.get_top_gguf_models(
        pipeline_filter="text-generation",
        min_params=23.0,
        max_params=150.0,
        limit_candidates=10000,
        top_n=25
    )
    ranker.print_top_models(top_large)
