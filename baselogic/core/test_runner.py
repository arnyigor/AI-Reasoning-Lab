import time
import json
import importlib
from pathlib import Path
from typing import Dict, Any, List
import logging

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±–∞ –Ω–∞—à–∏—Ö –∫–ª–∞—Å—Å–∞-–∫–ª–∏–µ–Ω—Ç–∞
from .llm_client import OllamaClient
from .http_client import OpenAICompatibleClient

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–µ—Ä –¥–ª—è —ç—Ç–æ–≥–æ –º–æ–¥—É–ª—è
log = logging.getLogger(__name__)


class TestRunner:
    """
    –û—Ä–∫–µ—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: –æ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–µ—Å—Ç–æ–≤ –∏ –≤—ã–±–æ—Ä–∞ –∫–ª–∏–µ–Ω—Ç–∞
    –¥–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–¥–∞—á, –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    """

    def __init__(self, config: Dict[str, Any]):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç TestRunner.

        Args:
            config (Dict[str, Any]): –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –∏–∑ config.yaml.
        """
        self.config = config
        self.test_generators = self._load_test_generators()
        self.results_dir = Path(__file__).parent.parent.parent / "results" / "raw"
        self.results_dir.mkdir(parents=True, exist_ok=True)

    def _load_test_generators(self) -> Dict[str, Any]:
        """
        –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –∏ –∏–Ω—Å—Ç–∞–Ω—Ü–∏–∏—Ä—É–µ—Ç –∫–ª–∞—Å—Å—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ —Ç–µ—Å—Ç–æ–≤
        –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ 'tests_to_run'.
        """
        generators = {}
        base_module_path = "baselogic.tests"

        if 'tests_to_run' not in self.config or not self.config['tests_to_run']:
            log.warning("–í 'config.yaml' –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω —Å–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤ 'tests_to_run'. –¢–µ—Å—Ç—ã –Ω–µ –±—É–¥—É—Ç –∑–∞–ø—É—â–µ–Ω—ã.")
            return generators

        for test_key in self.config['tests_to_run']:
            try:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ (t01_simple_logic) –≤ –∏–º—è –∫–ª–∞—Å—Å–∞ (SimpleLogicTestGenerator)
                class_name_parts = test_key.split('_')[1:]
                class_name = "".join([part.capitalize() for part in class_name_parts]) + "TestGenerator"

                module_name = f"{base_module_path}.{test_key}"
                module = importlib.import_module(module_name)
                generator_class = getattr(module, class_name)
                generators[test_key] = generator_class
                log.info("‚úÖ –¢–µ—Å—Ç '%s' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.", test_key)
            except (ImportError, AttributeError) as e:
                log.warning("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ—Å—Ç '%s'. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–º—è —Ñ–∞–π–ª–∞ –∏ –∫–ª–∞—Å—Å–∞. –û—à–∏–±–∫–∞: %s", test_key, e)
        return generators

    def run(self):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏ —Ç–µ—Å—Ç–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞.
        –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –Ω—É–∂–Ω—ã–π –∫–ª–∏–µ–Ω—Ç (Ollama –∏–ª–∏ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π) –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏.
        """
        if not self.config.get('models_to_test'):
            log.error("–í 'config.yaml' –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π 'models_to_test'. –ó–∞–ø—É—Å–∫ –æ—Ç–º–µ–Ω–µ–Ω.")
            return

        for model_config in self.config['models_to_test']:
            model_name = model_config.get('name')
            if not model_name:
                log.warning("–ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ñ–∏–≥ –º–æ–¥–µ–ª–∏ –±–µ–∑ –∏–º–µ–Ω–∏ ('name'). –ü—Ä–æ–ø—É—Å–∫.")
                continue

            model_options = model_config.get('options', {})
            client_type = model_config.get('client_type', 'ollama')  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 'ollama'

            log.info("=" * 20 + f" –ù–ê–ß–ê–õ–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ú–û–î–ï–õ–ò: {model_name} (–ö–ª–∏–µ–Ω—Ç: {client_type}) " + "=" * 20)

            # --- –§–∞–±—Ä–∏–∫–∞ –ö–ª–∏–µ–Ω—Ç–æ–≤: –í—ã–±–æ—Ä –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω—É–∂–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ ---
            client = None
            try:
                if client_type == "openai_compatible":
                    api_base = model_config.get('api_base')
                    if not api_base:
                        log.error(
                            "–î–ª—è –∫–ª–∏–µ–Ω—Ç–∞ 'openai_compatible' –Ω–µ —É–∫–∞–∑–∞–Ω 'api_base' –≤ –∫–æ–Ω—Ñ–∏–≥–µ. –ü—Ä–æ–ø—É—Å–∫ –º–æ–¥–µ–ª–∏ '%s'.",
                            model_name)
                        continue
                    client = OpenAICompatibleClient(
                        model_name=model_name,
                        api_base=api_base,
                        api_key=model_config.get('api_key'),  # –ü–µ—Ä–µ–¥–∞–µ–º api_key, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                        model_options=model_options
                    )
                elif client_type == "ollama":
                    client = OllamaClient(
                        model_name=model_name,
                        model_options=model_options
                    )
                else:
                    log.error("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∫–ª–∏–µ–Ω—Ç–∞ '%s' –¥–ª—è –º–æ–¥–µ–ª–∏ '%s'. –ü—Ä–æ–ø—É—Å–∫.", client_type, model_name)
                    continue
            except Exception as e:
                log.critical("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ '%s': %s", model_name, e,
                             exc_info=True)
                continue

            # --- –¶–∏–∫–ª –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ ---
            model_results = []
            num_runs = self.config.get('runs_per_test', 1)

            for test_key, generator_class in self.test_generators.items():
                log.info("---")
                log.info("‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: %s (%d –∑–∞–ø—É—Å–∫–æ–≤)", test_key, num_runs)
                log.info("---")

                for i in range(num_runs):
                    test_id = f"{test_key}_{i + 1}"
                    generator_instance = generator_class(test_id=test_id)

                    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è
                    test_data = generator_instance.generate()
                    prompt = test_data['prompt']
                    expected_output = test_data['expected_output']

                    # –ó–∞–ø—Ä–æ—Å –∫ LLM —á–µ—Ä–µ–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –∏ –∑–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏
                    start_time = time.perf_counter()
                    llm_response = client.query(prompt)
                    end_time = time.perf_counter()

                    # –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
                    is_correct = generator_instance.verify(llm_response, expected_output)

                    exec_time_ms = (end_time - start_time) * 1000
                    status = "‚úÖ" if is_correct else "‚ùå"
                    log.info("  %s –¢–µ—Å—Ç %s: –†–µ–∑—É–ª—å—Ç–∞—Ç = %s (–í—Ä–µ–º—è: %.0f ms)", status, test_id, is_correct, exec_time_ms)

                    # –°–±–æ—Ä –ø–æ–ª–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞
                    model_results.append({
                        "test_id": test_id,
                        "category": test_key,
                        "model_name": model_name,
                        "prompt": prompt,
                        "llm_response": llm_response,
                        "expected_output": expected_output,
                        "is_correct": is_correct,
                        "execution_time_ms": exec_time_ms
                    })

            self._save_results(model_name, model_results)
            log.info("=" * 20 + f" –ó–ê–í–ï–†–®–ï–ù–ò–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ú–û–î–ï–õ–ò: {model_name} " + "=" * 20)

    def _save_results(self, model_name: str, results: List[Dict[str, Any]]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª."""
        if not results:
            log.warning("–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ '%s'.", model_name)
            return

        timestamp = time.strftime("%Y%m%d_%H%M%S")
        safe_model_name = model_name.replace(":", "_").replace("/", "_")
        filename = self.results_dir / f"{safe_model_name}_{timestamp}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=4)
            log.info("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –º–æ–¥–µ–ª–∏ '%s' —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: %s", model_name, filename)
        except Exception as e:
            log.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ '%s': %s", filename, e, exc_info=True)
