import gc
import importlib
import json
import logging
import os
import time
from pathlib import Path
from typing import Dict, Any, List, Optional

import psutil
from msgspec.inspect import BoolType

from .adapter import AdapterLLMClient
from .client_factory import LLMClientFactory
# --- –ò–ó–ú–ï–ù–ï–ù–ò–ï 1: –û–±–Ω–æ–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å, –∫–æ—Ç–æ—Ä—ã–π –æ–∂–∏–¥–∞–µ—Ç TestRunner
from .interfaces import ILLMClient, LLMClientError
from .llm_client import LLMClient
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
from .plugin_manager import PluginManager
from .progress_tracker import ProgressTracker
from .reporter import Reporter
from .system_checker import SystemProfiler, get_hardware_tier

# –ü—Ä–æ—Å—Ç–æ –ø–æ–ª—É—á–∞–µ–º –ª–æ–≥–≥–µ—Ä –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞. –û–Ω —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!
log = logging.getLogger(__name__)


class TestRunner:
    """
    –û—Ä–∫–µ—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –ø–ª–∞–≥–∏–Ω–∞–º–∏, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
    –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≥–∏–±–∫–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∫–ª–∏–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä.
    """

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.test_generators = self._load_test_generators()
        project_root = Path(__file__).parent.parent.parent
        self.results_dir = project_root / "results" / "raw"
        self.results_dir.mkdir(parents=True, exist_ok=True)
        log.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –≤: %s", self.results_dir)

    def _load_test_generators(self) -> Dict[str, Any]:
        """
        –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–µ—Å—Ç—ã (–≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –∏ –ø–ª–∞–≥–∏–Ω—ã),
        –∞ –∑–∞—Ç–µ–º —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –∏—Ö —Å–æ–≥–ª–∞—Å–Ω–æ 'tests_to_run' –≤ –∫–æ–Ω—Ñ–∏–≥–µ.
        –ü–ª–∞–≥–∏–Ω—ã –∏–º–µ—é—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—é—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã —Å —Ç–µ–º –∂–µ –∏–º–µ–Ω–µ–º.
        """
        generators = {}
        base_module_path = "baselogic.tests"

        # --- –®–∞–≥ 1: –ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–µ–º –Ω–∞–π—Ç–∏ ---
        # –ò—â–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã tXX_*.py –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ tests
        tests_dir = Path(__file__).parent.parent / "tests"
        for test_file in tests_dir.glob("t[0-9][0-9]_*.py"):
            test_key = test_file.stem  # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ .py, –Ω–∞–ø—Ä–∏–º–µ—Ä 't01_simple_logic'
            try:
                class_name_parts = test_key.split('_')[1:]
                class_name = "".join([part.capitalize() for part in class_name_parts]) + "TestGenerator"

                module_name = f"{base_module_path}.{test_key}"
                module = importlib.import_module(module_name)
                generator_class = getattr(module, class_name)

                generators[test_key] = generator_class
                log.debug("‚úÖ –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç '%s' –Ω–∞–π–¥–µ–Ω –∏ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω.", test_key)
            except (ImportError, AttributeError) as e:
                log.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ '%s'. –û—à–∏–±–∫–∞: %s", test_file.name, e)

        # --- –®–∞–≥ 2: –ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï –ø–ª–∞–≥–∏–Ω—ã, –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –ø—Ä–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏ –∏–º–µ–Ω ---
        log.info("üîé –ü–æ–∏—Å–∫ –ø–ª–∞–≥–∏–Ω–æ–≤ —Ç–µ—Å—Ç–æ–≤...")
        plugin_manager = PluginManager()
        plugins = plugin_manager.discover_plugins()
        if plugins:
            log.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–ª–∞–≥–∏–Ω–æ–≤: {len(plugins)}")
            for plugin_name, plugin_class in plugins.items():
                if plugin_name in generators:
                    log.info(f"  - –ü–ª–∞–≥–∏–Ω '{plugin_name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω (–ü–ï–†–ï–û–ü–†–ï–î–ï–õ–Ø–ï–¢ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç).")
                else:
                    log.info(f"  - –ü–ª–∞–≥–∏–Ω '{plugin_name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")
                generators[plugin_name] = plugin_class
        else:
            log.info("–ü–ª–∞–≥–∏–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

        # --- –®–∞–≥ 3: –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã---
        tests_to_run_raw = self.config.get('tests_to_run', [])
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ–º —Å–æ —Å–ø–∏—Å–∫–æ–º, –¥–∞–∂–µ –µ—Å–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –ø—Ä–∏—à–ª–∞ —Å—Ç—Ä–æ–∫–∞
        if isinstance(tests_to_run_raw, str):
            tests_to_run_raw = [tests_to_run_raw]
        tests_to_run_set = set(tests_to_run_raw)
        if not tests_to_run_set:
            log.warning("–°–ø–∏—Å–æ–∫ 'tests_to_run' –≤ –∫–æ–Ω—Ñ–∏–≥–µ –ø—É—Å—Ç. –¢–µ—Å—Ç—ã –Ω–µ –±—É–¥—É—Ç –∑–∞–ø—É—â–µ–Ω—ã.")
            return {}  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å

        filtered_generators = {name: gen for name, gen in generators.items() if name in tests_to_run_set}

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã
        found_keys = set(filtered_generators.keys())
        missing_keys = tests_to_run_set - found_keys
        if missing_keys:
            log.warning(f"‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –∏–∑ 'tests_to_run' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏–≥–¥–µ: {', '.join(missing_keys)}")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–ª—é—á–∞–º (–∏–º–µ–Ω–∞–º —Ç–µ—Å—Ç–æ–≤)
        filtered_generators = dict(sorted(filtered_generators.items()))

        log.info(f"–ò—Ç–æ–≥–æ–≤—ã–π –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –∑–∞–ø—É—Å–∫–∞: {list(filtered_generators.keys())}")
        return filtered_generators

    def run(self):
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –∑–∞–ø—É—Å–∫ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
        """
        if not self.config.get('models_to_test'):
            log.error("–í 'config.yaml' –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π 'models_to_test'. –ó–∞–ø—É—Å–∫ –æ—Ç–º–µ–Ω–µ–Ω.")
            return

        # –ù–û–í–û–ï: –°–æ–±–∏—Ä–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –Ω–∞—á–∞–ª–µ
        profiler = SystemProfiler()
        system_info = profiler.get_system_info()
        hardware_tier = get_hardware_tier(system_info)

        log.info("=" * 80)
        log.info("üñ•Ô∏è  –°–ò–°–¢–ï–ú–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø")
        log.info("=" * 80)
        log.info(f"üè∑Ô∏è  –£—Ä–æ–≤–µ–Ω—å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è: {hardware_tier}")

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∫–∞–∫ –≤ main() —Ñ—É–Ω–∫—Ü–∏–∏ system_checker
        cpu_info = system_info['cpu']
        cpu_name = cpu_info.get('cpu_brand', cpu_info.get('model_name', cpu_info.get('processor_name', 'Unknown CPU')))
        log.info(f"üß† CPU: {cpu_name}")
        log.info(f"üíæ RAM: {system_info['memory']['total_ram_gb']} GB")

        for i, gpu in enumerate(system_info['gpus']):
            vram = gpu.get('memory_total_gb', 'N/A')
            gpu_type = gpu.get('type', 'unknown')
            log.info(f"üéÆ GPU {i}: {gpu['vendor']} {gpu['name']} ({vram} GB VRAM, {gpu_type})")

        if not system_info['gpus']:
            log.info("üéÆ GPU: –ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö GPU")

        # –û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...
        successful_models, failed_models = [], []
        num_runs = self.config.get('runs_per_test', 1)
        show_payload = self.config.get('show_payload', True)
        raw_save = self.config.get('runs_raw_save', 1)
        total_test_cases = len(self.test_generators) * num_runs * len(self.config['models_to_test'])

        progress = ProgressTracker(total_test_cases)

        try:
            for model_config in self.config['models_to_test']:
                model_name = model_config.get('name')
                if not model_name:
                    log.warning("–ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ñ–∏–≥ –º–æ–¥–µ–ª–∏ –±–µ–∑ –∏–º–µ–Ω–∏ ('name'). –ü—Ä–æ–ø—É—Å–∫.")
                    continue

                log.info("=" * 80)
                log.info("üöÄ –ù–ê–ß–ê–õ–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ú–û–î–ï–õ–ò: %s", model_name)
                log.info("=" * 80)

                try:
                    log.info("üîß –≠–¢–ê–ü 1: –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞...")
                    client = self._create_client_safely(model_config, show_payload)
                    if client is None:
                        failed_models.append((model_name, "–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞"))
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Ç–µ—Å—Ç—ã –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–µ
                        for _ in range(len(self.test_generators) * num_runs):
                            progress.update(model_name, "N/A")
                        continue

                    log.info("üìä –≠–¢–ê–ü 2: –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏...")
                    model_details = client.get_model_info()

                    log.info("üß™ –≠–¢–ê–ü 3: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤...")
                    model_results = self._run_tests_for_model(client, model_name, model_details, progress)

                    if raw_save:
                        log.info("üíæ –≠–¢–ê–ü 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
                        self._save_results(model_name, model_results)

                    if not model_results:
                        failed_models.append((model_name, "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç –º–æ–¥–µ–ª–∏"))
                    else:
                        successful_models.append(model_name)

                except Exception as e:
                    log.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏ %s: %s", model_name, e, exc_info=True)
                    failed_models.append((model_name, str(e)))
                    continue
        finally:
            progress.close()
        if raw_save:
            log.info("üìä –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–ß–ï–¢–ê –° –°–ò–°–¢–ï–ú–ù–û–ô –ò–ù–§–û–†–ú–ê–¶–ò–ï–ô:")
            try:
                reporter = Reporter(self.results_dir)
                report_content = reporter.generate_leaderboard_report()

                report_file = self.results_dir.parent / f"report_{hardware_tier}_{time.strftime('%Y%m%d_%H%M%S')}.md"
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(report_content)

                log.info(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
            except Exception as e:
                log.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")


    def _create_client_safely(self, model_config: Dict[str, Any], show_payload = True) -> Optional[ILLMClient]:
        """
        –°–æ–∑–¥–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç —á–µ—Ä–µ–∑ —Ñ–∞–±—Ä–∏–∫—É, –∞ –∑–∞—Ç–µ–º –æ–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç –µ–≥–æ –≤ LLMClient –∏ Adapter.
        """
        try:
            # –î–µ–ª–µ–≥–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –Ω–∞—à–µ–π —Ñ–∞–±—Ä–∏–∫–µ
            provider = LLMClientFactory.create_provider(model_config)

            # –û—Å—Ç–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ—Å—Ç–∞–µ—Ç—Å—è —Ç–æ–π –∂–µ
            new_llm_client = LLMClient(provider=provider, model_config=model_config, show_payload=show_payload)
            adapter = AdapterLLMClient(
                new_llm_client=new_llm_client,
                model_config=model_config
            )

            log.info("  ‚úÖ –ö–ª–∏–µ–Ω—Ç –∏ –∞–¥–∞–ø—Ç–µ—Ä —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã")
            return adapter

        except Exception as e:
            log.error("  ‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞: %s", e, exc_info=True)
            return None

    def _run_tests_for_model(self, client: ILLMClient, model_name: str, model_details: Dict[str, Any],
                             progress: ProgressTracker) -> List[Dict[str, Any]]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –æ–¥–Ω–æ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏."""
        model_results = []
        num_runs = self.config.get('runs_per_test', 1)
        log.info("  üß™ –í—Å–µ–≥–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ç–µ—Å—Ç–æ–≤: %d | –ó–∞–ø—É—Å–∫–æ–≤ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é: %d", len(self.test_generators), num_runs)

        for test_key, generator_class in self.test_generators.items():
            log.info("  --- üìù –ö–ê–¢–ï–ì–û–†–ò–Ø: %s ---", test_key)
            try:
                generator_instance = generator_class(test_id=test_key)
                for run_num in range(1, num_runs + 1):
                    test_id = f"{test_key}_{run_num}"
                    log.info("    üîç –¢–µ—Å—Ç %d/%d: %s", run_num, num_runs, test_id)

                    test_data = generator_instance.generate()

                    result = self._run_single_test_with_monitoring(
                        client, test_id, generator_instance, test_data,
                        model_name, model_details, test_key
                    )

                    if result:
                        model_results.append(result)

                    progress.update(model_name, test_key)
                    gc.collect()

            except Exception as e:
                log.error("    ‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ %s: %s", test_key, e, exc_info=True)
                for _ in range(num_runs - len(model_results) % num_runs):
                    progress.update(model_name, test_key)

        return model_results


    def _run_single_test_with_monitoring(self, client: ILLMClient, test_id: str,
                                         generator_instance: Any, test_data: Dict[str, Any],
                                         model_name: str, model_details: Dict[str, Any],
                                         test_category: str) -> Optional[Dict[str, Any]]:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–æ–ª—è–º–∏ –¥–ª—è system_info.
        """
        process = psutil.Process(os.getpid())
        try:
            prompt = test_data['prompt']
            expected_output = test_data['expected_output']

            log.info("      3Ô∏è‚É£ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏...")
            start_time = time.perf_counter()
            initial_ram = process.memory_info().rss / (1024 * 1024)

            response_struct = client.query(prompt)

            end_time = time.perf_counter()
            peak_ram = process.memory_info().rss / (1024 * 1024)
            exec_time_ms = (end_time - start_time) * 1000
            ram_usage_mb = peak_ram - initial_ram

            thinking_response = response_struct.get("thinking_response", "")
            llm_response = response_struct.get("llm_response", "")

            performance_metrics = response_struct.get("performance_metrics", {})
            performance_metrics['total_latency_ms'] = exec_time_ms
            performance_metrics['peak_ram_increment_mb'] = ram_usage_mb

            verification_result = generator_instance.verify(llm_response, expected_output)
            is_correct = verification_result.get('is_correct', False)

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            status = "‚úÖ –£–°–ü–ï–•" if is_correct else "‚ùå –ù–ï–£–î–ê–ß–ê"
            log.info("    %s (%.0f –º—Å): %s", status, exec_time_ms, test_id)

            details = verification_result.get('details', {})
            if details:
                log.info("      --- –î–µ—Ç–∞–ª–∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ ---")
                for key, value in details.items():
                    log.info("      - %s: %s", key, str(value)[:200])
                log.info("      --------------------------")

            if performance_metrics:
                self.log_performance_metrics(performance_metrics)

            # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –≤–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–æ–ª—è–º–∏
            return {
                "test_id": test_id,
                "model_name": model_name,
                "model_details": model_details,
                "category": test_category,  # ‚Üê –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û–ï –ü–û–õ–ï
                "prompt": prompt,

                # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è Verbosity (Reporter –∏—â–µ—Ç –∏–º–µ–Ω–Ω–æ —ç—Ç–∏)
                "thinking_response": thinking_response,  # ‚Üê –î–ª—è _calculate_verbosity
                "llm_response": llm_response,           # ‚Üê –î–ª—è _calculate_verbosity

                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                "thinking_log": thinking_response,
                "parsed_answer": llm_response,
                "raw_llm_output": f"<think>{thinking_response}</think>\n{llm_response}",

                "expected_output": expected_output,
                "is_correct": is_correct,
                "execution_time_ms": exec_time_ms,
                "verification_details": verification_result.get('details', {}),
                "performance_metrics": {k: v for k, v in performance_metrics.items() if v is not None}
            }

        except LLMClientError as e:
            log.error("      ‚ùå –û—à–∏–±–∫–∞ LLM –∫–ª–∏–µ–Ω—Ç–∞: %s", e)
            return None
        except Exception as e:
            log.error("      ‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç-–∫–µ–π—Å–µ %s: %s", test_id, e, exc_info=True)
            return None


    def _save_results(self, model_name: str, results: List[Dict[str, Any]]):
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π."""
        if not results:
            log.warning("  ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ '%s'", model_name)
            return

        # –î–û–ë–ê–í–õ–ï–ù–ò–ï: –°–æ–±–∏—Ä–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        profiler = SystemProfiler()
        system_info = profiler.get_system_info()
        hardware_tier = get_hardware_tier(system_info)

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∫ –∫–∞–∂–¥–æ–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
        enhanced_results = []
        for result in results:
            enhanced_result = result.copy()
            enhanced_result['system_info'] = system_info
            enhanced_result['hardware_tier'] = hardware_tier
            enhanced_result['benchmark_timestamp'] = time.time()
            enhanced_results.append(enhanced_result)

        timestamp = time.strftime("%Y%m%d_%H%M%S")
        safe_model_name = model_name.replace(":", "_").replace("/", "_")
        filename = self.results_dir / f"{safe_model_name}_{hardware_tier}_{timestamp}.json"

        try:
            log.info("  üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª: %s", filename.name)
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(enhanced_results, f, ensure_ascii=False, indent=4, default=str)
            log.info("  ‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω (%d –∑–∞–ø–∏—Å–µ–π)", len(enhanced_results))
        except Exception as e:
            log.error("  ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: %s", e, exc_info=True)


    def log_performance_metrics(self, performance_metrics: Dict[str, Any]):
        if not performance_metrics:
            log.info("      --- –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ --- –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            log.info("      ---------------------------------")
            return

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        model = performance_metrics.get('model', 'unknown')
        total_duration_ns = performance_metrics.get('total_duration', 0)
        load_duration_ns = performance_metrics.get('load_duration', 0)
        prompt_eval_count = performance_metrics.get('prompt_eval_count', 0)
        prompt_eval_duration_ns = performance_metrics.get('prompt_eval_duration', 0)
        eval_count = performance_metrics.get('eval_count', 0)
        eval_duration_ns = performance_metrics.get('eval_duration', 0)
        time_to_first_token_ms = performance_metrics.get('time_to_first_token_ms')
        total_latency_ms = performance_metrics.get('total_latency_ms')
        peak_ram_mb = performance_metrics.get('peak_ram_increment_mb')

        # –í—ã—á–∏—Å–ª—è–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        prompt_tps = (prompt_eval_count / (prompt_eval_duration_ns / 1e9)) if prompt_eval_duration_ns > 0 else 0
        output_tps = (eval_count / (eval_duration_ns / 1e9)) if eval_duration_ns > 0 else 0
        total_tps = (eval_count / (total_duration_ns / 1e9)) if total_duration_ns > 0 else 0

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        load_time_ms = load_duration_ns / 1e6
        prompt_eval_time_ms = prompt_eval_duration_ns / 1e6
        eval_time_ms = eval_duration_ns / 1e6
        total_time_ms = total_duration_ns / 1e6

        # –ù–∞—á–∞–ª–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        log.info("      --- –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ---")
        log.info("      –ú–æ–¥–µ–ª—å: %s", model)

        log.info("      üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: %.2f –º—Å", load_time_ms)

        log.info("      üì• –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ (%d —Ç–æ–∫–µ–Ω–æ–≤): %.2f –º—Å ‚Üí %.2f —Ç–æ–∫/—Å",
                 prompt_eval_count, prompt_eval_time_ms, prompt_tps)

        if time_to_first_token_ms is not None:
            log.info("      ‚è±Ô∏è  –í—Ä–µ–º—è –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞: %.0f –º—Å", time_to_first_token_ms)

        log.info("      üñ®Ô∏è  –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ (%d —Ç–æ–∫–µ–Ω–æ–≤): %.2f –º—Å ‚Üí %.2f —Ç–æ–∫/—Å",
                 eval_count, eval_time_ms, output_tps)

        log.info("      üïê –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: %.2f –º—Å (–ø–æ —Ç–∞–π–º–µ—Ä—É: %.2f –º—Å)", total_time_ms,
                 total_latency_ms or total_time_ms)

        if peak_ram_mb is not None:
            log.info("      üìà –ü–∏–∫–æ–≤–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ RAM: %.1f –ú–ë", peak_ram_mb)

        if total_tps > 0:
            log.info("      üöÄ –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: %.2f —Ç–æ–∫/—Å (–ø–æ –æ–±—â–µ–º—É –≤—Ä–µ–º–µ–Ω–∏)", total_tps)

        log.info("      ---------------------------------")

    def run_benchmarks_with_system_info(self):
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ benchmark'–æ–≤ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Å–∏—Å—Ç–µ–º—ã.
        """

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ñ–∏–ª–µ—Ä –∏ –ø–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ
        profiler = SystemProfiler()
        system_info = profiler.get_system_info()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        hardware_tier = get_hardware_tier(system_info)

        log.info(f"üñ•Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ —É—Ä–æ–≤–Ω—è: {hardware_tier}")
        log.info(f"üß† CPU: {system_info['cpu']['processor_name']}")
        log.info(f"üíæ RAM: {system_info['memory']['total_ram_gb']} GB")

        for gpu in system_info['gpus']:
            vram = gpu.get('memory_total_gb', 'N/A')
            log.info(f"üéÆ GPU: {gpu['vendor']} {gpu['name']} ({vram} GB VRAM)")

        # # –ó–∞–ø—É—Å–∫–∞–µ–º benchmark'–∏
        # results = run_benchmarks(models, tasks)
        #
        # # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
        # results = log_system_info(results)
        # results['hardware_tier'] = hardware_tier
        #
        # # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        # save_results(results, f'results_{hardware_tier}.json')
        #
        # return results
