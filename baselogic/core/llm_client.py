# baselogic/clients/ollama_client.py
import logging
import re
from typing import Dict, Any, Optional

import ollama

# –í–∞—à–∏ –∏–º–ø–æ—Ä—Ç—ã
from .base_client import BaseLLMClient
from .interfaces import LLMResponseError, LLMConnectionError
from .types import ModelOptions

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à –ª–æ–≥–≥–µ—Ä
log = logging.getLogger(__name__)

import time


class OllamaClient(BaseLLMClient):
    """
    –ö–ª–∞—Å—Å-–∫–ª–∏–µ–Ω—Ç –¥–ª—è –∏–Ω–∫–∞–ø—Å—É–ª—è—Ü–∏–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å API Ollama.
    –° –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫.
    """

    def __init__(self, model_name: str, model_options: Optional[ModelOptions] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç.
        """
        # –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑—ã–≤–∞–µ–º super().__init__(), —á—Ç–æ–±—ã –≤—Å–µ –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è –±—ã–ª–∏ –Ω–∞ –º–µ—Å—Ç–µ
        super().__init__(model_name, model_options)

        # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç Ollama –ó–î–ï–°–¨ ---
        try:
            self.client = ollama.Client()
        except Exception as e:
            # –ï—Å–ª–∏ Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞, —ç—Ç–æ –≤—ã–∑–æ–≤–µ—Ç –æ—à–∏–±–∫—É. –ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º –µ–µ.
            raise LLMConnectionError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–∏—Å –∑–∞–ø—É—â–µ–Ω. –û—à–∏–±–∫–∞: {e}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å, –Ω–æ –ù–ï –∑–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–æ–≥—Ä–∞–º–º—É
        skip_validation = self.model_options.get('skip_model_validation', False)
        if not skip_validation:
            self._check_model_exists()
        else:
            log.warning("‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω–∞")

        # –¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –µ—Å—Ç—å, –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        self._configure_context_window()

    def _configure_context_window(self):
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞.
        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
        1. –ó–Ω–∞—á–µ–Ω–∏–µ –∏–∑ inference_opts (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ .env).
        2. –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–∑ `ollama show`.
        3. –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (4096).
        """
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä—É—á–Ω—É—é —É—Å—Ç–∞–Ω–æ–≤–∫—É
        manual_num_ctx = self.inference_opts.get('num_ctx')
        if manual_num_ctx:
            log.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –∑–∞–¥–∞–Ω–Ω—ã–π –≤—Ä—É—á–Ω—É—é: {manual_num_ctx}")
            self.generation_opts['num_ctx'] = int(manual_num_ctx)
            return

        # 2. –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        log.info(f"–†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ –∑–∞–¥–∞–Ω –≤—Ä—É—á–Ω—É—é. –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ '{self.model_name}'...")
        try:
            model_info = self.client.show(self.model_name)

            # –ò—â–µ–º –∫–ª—é—á –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            context_length = model_info.get('details', {}).get('parameter_size_context')

            # Fallback: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if not context_length:
                params_str = model_info.get('parameters', '')
                match = re.search(r'num_ctx\s+(\d+)', params_str)
                if match:
                    context_length = int(match.group(1))

            # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–µ—Ñ–æ–ª—Ç
            if not context_length:
                context_length = 4096
                log.warning(
                    f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è '{self.model_name}'. "
                    f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {context_length}. "
                    f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–∫–∞–∑–∞—Ç—å 'num_ctx' –≤—Ä—É—á–Ω—É—é –≤ .env."
                )
            else:
                log.info(f"‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {context_length}")

            self.generation_opts['num_ctx'] = int(context_length)

        except ollama.ResponseError as e:
            log.warning(
                f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å '{self.model_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø—Ä–∏ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –û—à–∏–±–∫–∞: {e.status_code}"
            )
            self._set_default_context()
        except Exception as e:
            log.warning(
                f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ä–∞–∑–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}. "
                f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 4096."
            )
            self._set_default_context()

    def _set_default_context(self, default_value: int = 4096):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
        self.generation_opts['num_ctx'] = default_value

    def _check_model_exists(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ `ollama.list()` —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π,
        –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–º–µ–Ω–∏.
        """
        try:
            log.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏ '%s' —á–µ—Ä–µ–∑ API Ollama...", self.model_name)
            # self.client.list() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å, –Ω–∞–º –Ω—É–∂–µ–Ω –∫–ª—é—á 'models'
            models_list = self.client.list().get('models', [])

            if not models_list:
                log.warning("‚ö†Ô∏è –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –æ—Ç Ollama –ø—É—Å—Ç. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏.")
                return

            # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏ ---
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º .get() –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–∞ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–ª—é—á–∞: 'name' –∏ 'model'
            available_models = []
            for m in models_list:
                # m - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å. .get() –±–µ–∑–æ–ø–∞—Å–µ–Ω –∏ –≤–µ—Ä–Ω–µ—Ç None, –µ—Å–ª–∏ –∫–ª—é—á–∞ –Ω–µ—Ç.
                # –ú—ã –ø—Ä–æ–≤–µ—Ä—è–µ–º 'name', –∏ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º 'model'.
                model_identifier = m.get('name') or m.get('model')
                if model_identifier:
                    available_models.append(model_identifier)
                else:
                    log.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–ª—é—á 'name' –∏–ª–∏ 'model' –≤ —ç–ª–µ–º–µ–Ω—Ç–µ —Å–ø–∏—Å–∫–∞: {m}")

            if not available_models:
                log.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–º–µ–Ω–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.")
                return

            # –û—Å—Ç–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            target_base_name = self.model_name.split(':')[0]
            is_found = any(
                self.model_name == m_name or target_base_name == m_name.split(':')[0]
                for m_name in available_models
            )

            if is_found:
                log.info("‚úÖ –ú–æ–¥–µ–ª—å '%s' –Ω–∞–π–¥–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ.", self.model_name)
            else:
                log.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª—å '%s' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: %s",
                            self.model_name, [m[:40] for m in available_models[:5]])

        except Exception as e:
            # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É, –Ω–æ –Ω–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            log.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π: %s. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É.", e, exc_info=True)

    def get_model_info(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏. –ü–µ—Ä–µ–ø–∏—Å–∞–Ω –¥–ª—è –±–æ–ª—å—à–µ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.
        """
        base_info = super().get_model_info()
        try:
            log.debug("–ó–∞–ø—Ä–æ—Å –¥–µ—Ç–∞–ª–µ–π –¥–ª—è –º–æ–¥–µ–ª–∏: %s", self.model_name)
            response = self.client.show(self.model_name)

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –±–µ–∑–æ–ø–∞—Å–Ω–æ
            base_info['details'] = response.get('details', {})
            base_info['parameters'] = response.get('parameters', 'N/A')
            base_info['modelfile'] = response.get('modelfile', 'N/A')

            return base_info
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–µ—Ç–∞–ª–µ–π –º–æ–¥–µ–ª–∏ –æ—Ç Ollama: {e}"
            log.error(error_msg)
            base_info['error'] = error_msg
            return base_info

    def _execute_query(self, user_prompt: str) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Ollama –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        —Å "–º—ã—Å–ª—è–º–∏" –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–µ–∂–∏–º—ã 'think' –∏ 'stream'.
        """
        messages = self._prepare_messages(user_prompt)

        use_think = self.inference_opts.get('think', False)
        use_stream = self.inference_opts.get('stream', False)
        is_streaming_mode = use_think or use_stream

        # === –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –õ–û–ì–ò–†–£–ï–ú –ü–†–û–ú–ü–¢ ===
        log.info("üîç –ü–†–û–ú–ü–¢ –û–¢–ü–†–ê–í–õ–Ø–ï–¢–°–Ø:")
        for i, msg in enumerate(messages):
            log.info("  –°–æ–æ–±—â–µ–Ω–∏–µ %d: %s", i, msg)
        log.info("üîç –ü–ê–†–ê–ú–ï–¢–†–´: stream=%s, think=%s", is_streaming_mode, use_think)
        log.info("üîç –û–ü–¶–ò–ò –ì–ï–ù–ï–†–ê–¶–ò–ò: %s", self.generation_opts)

        log.info("    üöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏ '%s' (think=%s, stream=%s)...",
                 self.model_name, use_think, is_streaming_mode)

        try:
            # === –ó–ê–°–ï–ö–ê–ï–ú –í–†–ï–ú–Ø API –í–´–ó–û–í–ê ===
            api_start_time = time.time()
            log.info("üöÄ API –≤—ã–∑–æ–≤ –Ω–∞—á–∞–ª—Å—è –≤ %s", time.strftime("%H:%M:%S"))

            # –ï–¥–∏–Ω—ã–π –≤—ã–∑–æ–≤ API –¥–ª—è –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤
            response_iterator = self.client.chat(
                model=self.model_name,
                messages=messages,
                options=self.generation_opts,
                think=use_think,
                stream=is_streaming_mode
            )

            log.info("‚ö° API –æ—Ç–≤–µ—Ç–∏–ª –∑–∞ %.3f —Å–µ–∫", time.time() - api_start_time)

            thinking_parts = []
            content_parts = []
            has_printed_thinking_header = False
            has_printed_answer_header = False

            if not is_streaming_mode:
                response_iterator = [response_iterator]

            stream_start_time = time.time()

            # === –ü–ï–†–ï–î–ê–ï–ú max_chunks –ö–ê–ö –ü–ê–†–ê–ú–ï–¢–† ===
            max_chunks = self.inference_opts.get('max_chunks', 1000)

            self.process_query(content_parts, has_printed_answer_header, has_printed_thinking_header,
                               response_iterator, thinking_parts, max_chunks)

            elapsed_time = time.time() - stream_start_time
            log.info("    ‚è±Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∏–º–∞ –∑–∞–Ω—è–ª–∞ %.2f —Å–µ–∫—É–Ω–¥", elapsed_time)

            print()  # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏

            # 3. –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            final_thinking = "".join(thinking_parts).strip()
            final_content = "".join(content_parts).strip()

            if not final_content and not final_thinking:
                raise LLMResponseError("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")

            log.info("    ‚úÖ –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω.")

            return {
                "thinking_response": final_thinking,
                "llm_response": final_content,
            }

        except ollama.ResponseError as e:
            log.error("    üö´ Ollama API Error (Status %d): %s", e.status_code, e.error)
            return {
                "thinking_response": "",
                "llm_response": f"[API_ERROR] {e.error}"
            }
        except Exception as e:
            log.error("    üí• –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: %s", e, exc_info=True)
            return {
                "thinking_response": "",
                "llm_response": f"[ERROR] {str(e)}"
            }

    def process_query(
            self,
            content_parts: list[str],
            has_printed_answer_header: bool,
            has_printed_thinking_header: bool,
            response_iterator,
            thinking_parts: list[str],
            max_chunks: int = 1000
    ) -> None:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç Ollama, —Ä–∞–∑–¥–µ–ª—è—è ¬´–º—ã—Å–ª–∏¬ª (thinking) –∏ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        ----------
        content_parts : list[str]
            –°–ø–∏—Å–æ–∫, –∫—É–¥–∞ –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è —á–∞—Å—Ç–∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.
        has_printed_answer_header : bool
            –§–ª–∞–≥, –ø–æ–∫–∞–∑—ã–≤–∞—é—â–∏–π, –ø–µ—á–∞—Ç–∞–ª–∏ –ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ [ANSWER].
        has_printed_thinking_header : bool
            –§–ª–∞–≥, –ø–æ–∫–∞–∑—ã–≤–∞—é—â–∏–π, –ø–µ—á–∞—Ç–∞–ª–∏ –ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ [THINKING].
        response_iterator : Iterable
            –ò—Ç–µ—Ä–∞—Ç–æ—Ä chunk-–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö Ollama.
        thinking_parts : list[str]
            –°–ø–∏—Å–æ–∫, –∫—É–¥–∞ –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è —á–∞—Å—Ç–∏ ¬´–º—ã—Å–ª–µ–π¬ª –º–æ–¥–µ–ª–∏.
        max_chunks : int, optional
            –ó–∞—â–∏—Ç–Ω—ã–π –ª–∏–º–∏—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ chunk-–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1000).
        """
        import time

        chunk_counter = 0
        stream_start = time.time()

        for chunk in response_iterator:
            chunk_counter += 1
            # current_time = time.time() - stream_start
            # log.info("‚è±Ô∏è Chunk #%d —á–µ—Ä–µ–∑ %.3f —Å–µ–∫", chunk_counter, current_time)

            # === –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–µ–π –∏–∑ chunk'–∞ ===
            try:
                done = getattr(chunk, "done", False) if hasattr(chunk, "done") else chunk.get("done", False)
                message = getattr(chunk, "message", {}) if hasattr(chunk, "message") else chunk.get("message", {})

                if isinstance(message, dict):
                    content_part  = message.get("content")
                    thinking_part = message.get("thinking")
                    finish_reason = message.get("finish_reason")
                else:  # message –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—ä–µ–∫—Ç–æ–º
                    content_part  = getattr(message, "content",  None) if message else None
                    thinking_part = getattr(message, "thinking", None) if message else None
                    finish_reason = getattr(message, "finish_reason", None) if message else None
            except Exception as exc:
                log.error("–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ chunk #%d: %s", chunk_counter, exc)
                content_part = thinking_part = finish_reason = None
                done = False

            # === –ü–µ—á–∞—Ç—å –∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ thinking ===
            if thinking_part:
                if not has_printed_thinking_header:
                    print("\n    [THINKING]: ", end="", flush=True)
                    has_printed_thinking_header = True
                print(thinking_part, end="", flush=True)
                thinking_parts.append(thinking_part)

            # === –ü–µ—á–∞—Ç—å –∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ content ===
            if content_part:
                if not has_printed_answer_header:
                    if has_printed_thinking_header:
                        print()  # –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ –±–ª–æ–∫–∞ thinking
                    print("    [ANSWER]:   ", end="", flush=True)
                    has_printed_answer_header = True
                print(content_part, end="", flush=True)
                content_parts.append(content_part)

            # === –£—Å–ª–æ–≤–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è ===
            if done:
                log.info("    ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–µ—Ä—à–∏–ª–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é (done=True) –Ω–∞ chunk #%d", chunk_counter)
                break

            if finish_reason:
                log.info("    ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–µ—Ä—à–∏–ª–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é (finish_reason=%s) –Ω–∞ chunk #%d",
                         finish_reason, chunk_counter)
                break

            # === –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Å—Ç—Ä–∏–º–∞ ===
            if chunk_counter > max_chunks:
                log.warning("‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç chunk'–æ–≤ (%d) ‚Äî –ø—Ä–µ—Ä—ã–≤–∞–µ–º —Å—Ç—Ä–∏–º.", max_chunks)
                break

