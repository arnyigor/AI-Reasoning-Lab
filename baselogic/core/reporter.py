import json
import logging
import math
import re
import time
from pathlib import Path
from typing import Tuple, Dict, Any, Optional

import numpy as np
import pandas as pd

log = logging.getLogger(__name__)


def wilson_score_interval(
        successes: int,
        total: int,
        confidence: float = 0.95
) -> Tuple[float, float]:
    """–í—ã—á–∏—Å–ª—è–µ—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –í–∏–ª—å—Å–æ–Ω–∞ –¥–ª—è –±–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–π –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏."""
    if total == 0:
        return 0.0, 1.0
    z = 1.959963984540054  # –¥–ª—è 95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
    p_hat = float(successes) / total
    part1 = p_hat + (z * z) / (2 * total)
    part2 = z * math.sqrt((p_hat * (1 - p_hat)) / total + (z * z) / (4 * total * total))
    denominator = 1 + (z * z) / total
    lower_bound = (part1 - part2) / denominator
    upper_bound = (part1 + part2) / denominator
    return lower_bound, upper_bound


def safe_get_hardware_tier(hardware_tier) -> Optional[str]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ hardware_tier —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π NaN –∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤."""
    if hardware_tier is None:
        return None
    if isinstance(hardware_tier, str) and hardware_tier.lower() not in ['nan', 'none', '']:
        return hardware_tier
    if isinstance(hardware_tier, float) and not (math.isnan(hardware_tier) or math.isinf(hardware_tier)):
        return str(hardware_tier)
    return None


def safe_get_dict(obj: Any, key: str, default: Any = None) -> Any:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å–ª–æ–≤–∞—Ä—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ç–∏–ø–∞."""
    if isinstance(obj, dict):
        return obj.get(key, default)
    return default


class Reporter:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –∫–ª–∞—Å—Å Reporter —Å –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ NaN –∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤.

    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—ã—Ä—ã–µ JSON-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è LLM, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∏—Ö —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏,
    –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–∞–º–æ–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–µ–º—ã–π –æ—Ç—á–µ—Ç –≤ Markdown.

    –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏:
    - –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ NaN –∑–Ω–∞—á–µ–Ω–∏–π –≤ hardware_tier
    - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º –º–µ—Ç–æ–¥–æ–≤ —Å–ª–æ–≤–∞—Ä–µ–π
    - –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö
    - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏
    """

    def __init__(self, results_dir: Path):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Reporter —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        self.results_dir = results_dir
        self.history_path = self.results_dir.parent / "history.json"

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.all_results: pd.DataFrame = self._load_all_results()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (—Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π)
        self.system_info_summary = self._extract_system_info_summary()
        self.hardware_tier = self._extract_hardware_tier()

        # –û—Ç–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        self.context_stress_results = pd.DataFrame()
        if 'category' in self.all_results.columns and 't_context_stress' in self.all_results['category'].unique():
            self.context_stress_results = self.all_results[self.all_results['category'] == 't_context_stress'].copy()
            log.info(f"–ù–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {len(self.context_stress_results)} –∑–∞–ø–∏—Å–µ–π.")

        log.info(f"Reporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {len(self.all_results)} –∑–∞–ø–∏—Å–µ–π, hardware_tier: {self.hardware_tier}")

    def _load_all_results(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ JSON —Ñ–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏."""
        all_data = []
        json_files = sorted(list(self.results_dir.glob("*.json")))
        log.info("–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—Ç—á–µ—Ç–∞: %d", len(json_files))

        for json_file in json_files:
            try:
                data = pd.read_json(json_file)
                if not data.empty:
                    all_data.append(data)
                    log.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª {json_file.name}: {len(data)} –∑–∞–ø–∏—Å–µ–π")
            except Exception as e:
                log.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ %s: %s", json_file, e)

        if not all_data:
            log.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞.")
            return pd.DataFrame()

        combined_data = pd.concat(all_data, ignore_index=True)
        log.info("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: %d", len(combined_data))
        return combined_data

    def _extract_system_info_summary(self) -> Dict[str, Any]:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        if self.all_results.empty or 'system_info' not in self.all_results.columns:
            log.warning("–°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö.")
            return {}

        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å —Å –≤–∞–ª–∏–¥–Ω–æ–π —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        for idx, row in self.all_results.iterrows():
            system_info_raw = row['system_info']

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º NaN –∏ None –∑–Ω–∞—á–µ–Ω–∏—è
            if pd.isna(system_info_raw) or system_info_raw is None:
                continue

            if isinstance(system_info_raw, str):
                try:
                    system_info = json.loads(system_info_raw)
                    if isinstance(system_info, dict):
                        log.info("–°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–∞ –∏–∑ –∑–∞–ø–∏—Å–∏ #%d.", idx)
                        return system_info
                except json.JSONDecodeError:
                    continue
            elif isinstance(system_info_raw, dict):
                log.info("–°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–∞ –∏–∑ –∑–∞–ø–∏—Å–∏ #%d.", idx)
                return system_info_raw

        log.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤–∞–ª–∏–¥–Ω—É—é —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö.")
        return {}

    def _extract_hardware_tier(self) -> Optional[str]:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        if self.all_results.empty or 'hardware_tier' not in self.all_results.columns:
            # –ï—Å–ª–∏ –Ω–µ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö, –ø—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–∑ system_info
            if self.system_info_summary:
                try:
                    from .system_checker import get_hardware_tier
                    tier = get_hardware_tier(self.system_info_summary)
                    return safe_get_hardware_tier(tier)
                except ImportError:
                    log.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å get_hardware_tier –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Ä–æ–≤–Ω—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è.")
            return None

        # –ë–µ—Ä–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è hardware_tier, –∏—Å–∫–ª—é—á–∞—è NaN
        hardware_tiers = self.all_results['hardware_tier'].dropna().unique()

        # –§–∏–ª—å—Ç—Ä—É–µ–º NaN –∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        valid_tiers = []
        for tier in hardware_tiers:
            valid_tier = safe_get_hardware_tier(tier)
            if valid_tier:
                valid_tiers.append(valid_tier)

        if len(valid_tiers) >= 1:
            selected_tier = valid_tiers[0]
            if len(valid_tiers) > 1:
                log.warning(
                    f"–ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —É—Ä–æ–≤–Ω–µ–π –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è: {valid_tiers}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–≤—ã–π: {selected_tier}")
            return selected_tier

        log.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –≤ –¥–∞–Ω–Ω—ã—Ö.")
        return None

    def _to_markdown_table(self, df: pd.DataFrame) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç DataFrame –≤ Markdown —Ç–∞–±–ª–∏—Ü—É."""
        if df.empty:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n"
        try:
            return df.fillna("N/A").to_markdown(index=False) + "\n"
        except ImportError:
            log.error("–î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Markdown-—Ç–∞–±–ª–∏—Ü —Ç—Ä–µ–±—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'tabulate'. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install tabulate")
            return "–û—à–∏–±–∫–∞: –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'tabulate' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.\n"

    def _calculate_verbosity(self, df: pd.DataFrame) -> pd.Series:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Ä–∞—Å—á–µ—Ç –ò–Ω–¥–µ–∫—Å–∞ –ë–æ–ª—Ç–ª–∏–≤–æ—Å—Ç–∏ –¥–ª—è thinking-–º–æ–¥–µ–ª–µ–π.

        –ü—Ä–∞–≤–∏–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏–∑:
        1. –û—Ç–¥–µ–ª—å–Ω–æ–≥–æ –ø–æ–ª—è 'thinking_response'
        2. <think>...</think> –±–ª–æ–∫–æ–≤ –≤–Ω—É—Ç—Ä–∏ 'llm_response'

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ–ª—é thinking —Ç–µ–∫—Å—Ç–∞ –æ—Ç –æ–±—â–µ–≥–æ –æ–±—ä–µ–º–∞ –≤—ã–≤–æ–¥–∞ –º–æ–¥–µ–ª–∏.
        """
        if df.empty:
            return pd.Series(dtype=float, name='Verbosity_Index')

        df_work = df.copy()

        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        required_columns = ['llm_response', 'thinking_response']
        for col in required_columns:
            if col not in df_work.columns:
                df_work[col] = ""

        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
        df_work['llm_response'] = df_work['llm_response'].fillna("")
        df_work['thinking_response'] = df_work['thinking_response'].fillna("")

        def get_thinking_length(llm_resp, thinking_resp):
            """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–ª–∏–Ω—É –≤—Å–µ–≥–æ thinking —Ç–µ–∫—Å—Ç–∞."""
            total_thinking = str(thinking_resp)

            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ <think>...</think> –±–ª–æ–∫–∏
            think_blocks = re.findall(r'<think>(.*?)</think>', str(llm_resp), re.DOTALL | re.IGNORECASE)
            for block in think_blocks:
                total_thinking += block

            return len(total_thinking)

        def get_answer_length(llm_resp):
            """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–ª–∏–Ω—É —á–∏—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ thinking –±–ª–æ–∫–æ–≤."""
            clean_answer = re.sub(r'<think>.*?</think>', '', str(llm_resp), flags=re.DOTALL | re.IGNORECASE)
            return len(clean_answer.strip())

        # –ü—Ä–æ—Å—Ç—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–ª–∏–Ω
        df_work['thinking_len'] = df_work.apply(
            lambda row: get_thinking_length(row['llm_response'], row['thinking_response']), axis=1
        )
        df_work['answer_len'] = df_work.apply(
            lambda row: get_answer_length(row['llm_response']), axis=1
        )
        df_work['total_len'] = df_work['thinking_len'] + df_work['answer_len']

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –º–æ–¥–µ–ª—è–º
        model_stats = df_work.groupby('model_name')[['thinking_len', 'total_len']].sum()

        # –°—á–∏—Ç–∞–µ–º –¥–æ–ª—é thinking
        verbosity = pd.Series(0.0, index=model_stats.index, name='Verbosity_Index')

        for model in model_stats.index:
            total = model_stats.loc[model, 'total_len']
            if total > 0:
                verbosity[model] = model_stats.loc[model, 'thinking_len'] / total

        return verbosity

    def _calculate_comprehensiveness(self, df: pd.DataFrame) -> pd.Series:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è —Ä–∞—Å—á–µ—Ç–∞ Coverage.
        –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ —É—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞.
        """
        if 'category' not in df.columns or df['category'].nunique() == 0:
            return pd.Series(0.0, index=df['model_name'].unique(), name="Comprehensiveness")

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°—á–∏—Ç–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ—Ç –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞, –∞ –Ω–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ
        total_unique_categories = self.all_results['category'].nunique()

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£—á–∏—Ç—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        all_models_coverage = self.all_results.groupby('model_name')['category'].nunique()

        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ —Ç–µ–∫—É—â–µ–π –≤—ã–±–æ—Ä–∫–∏
        filtered_models = df['model_name'].unique()

        # –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        comprehensiveness_index = pd.Series(0.0, index=filtered_models, name="Comprehensiveness")

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        for model in filtered_models:
            if model in all_models_coverage.index:
                comprehensiveness_index[model] = all_models_coverage[model] / total_unique_categories
            else:
                comprehensiveness_index[model] = 0.0

        return comprehensiveness_index

    def _calculate_leaderboard(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è —Ä–∞—Å—á–µ—Ç–∞ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–∞ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
        """
        if df.empty:
            return pd.DataFrame()

        # --- –≠—Ç–∞–ø 1: –ê–≥—Ä–µ–≥–∞—Ü–∏—è –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ ---
        metrics = df.groupby('model_name').agg(
            Successes=('is_correct', 'sum'),
            Total_Runs=('is_correct', 'count'),
            Avg_Time_ms=('execution_time_ms', 'mean')
        )

        # --- –≠—Ç–∞–ø 2: –†–∞—Å—á–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ ---
        verbosity = self._calculate_verbosity(df)
        comprehensiveness = self._calculate_comprehensiveness(df)

        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø–æ –∏–Ω–¥–µ–∫—Å—É
        metrics = metrics.join(verbosity, how='left').join(comprehensiveness, how='left')

        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –Ω—É–ª—è–º–∏ –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Ç—Ä–∏–∫
        metrics['Verbosity_Index'] = metrics['Verbosity_Index'].fillna(0.0)
        metrics['Comprehensiveness'] = metrics['Comprehensiveness'].fillna(0.0)

        # --- –≠—Ç–∞–ø 3: –†–∞—Å—á–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π ---
        metrics['Accuracy'] = (metrics['Successes'] / metrics['Total_Runs']).fillna(0)
        metrics['Trust_Score'] = metrics.apply(
            lambda row: wilson_score_interval(int(row['Successes']), int(row['Total_Runs']))[0],
            axis=1
        )

        # --- –≠—Ç–∞–ø 4: –†–∞–±–æ—Ç–∞ —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ ---
        history_df = self._load_history()
        metrics['Accuracy_Change'] = 0.0

        if not history_df.empty:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            metrics = metrics.join(history_df.add_suffix('_prev'), how='left')

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏
            metrics['Accuracy_Change'] = (
                    metrics['Accuracy'] - metrics['Accuracy_prev'].fillna(metrics['Accuracy'])
            ).fillna(0)

        # --- –≠—Ç–∞–ø 5: –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ Trust Score ---
        metrics.sort_values(by='Trust_Score', ascending=False, inplace=True)
        metrics.reset_index(inplace=True)
        metrics.insert(0, 'Rank', range(1, len(metrics) + 1))
        metrics.set_index('model_name', inplace=True)

        # --- –≠—Ç–∞–ø 6: –§—É–Ω–∫—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π ---
        def format_with_indicator(value, change, format_str):
            """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è (‚ñ≤‚ñº‚ñ¨)."""
            indicator, change_str = "", ""
            threshold = 0.001

            if change > threshold:
                indicator, change_str = " ‚ñ≤", f" (+{change:.1%})"
            elif change < -threshold:
                indicator, change_str = " ‚ñº", f" ({change:.1%})"
            elif not history_df.empty:
                indicator = " ‚ñ¨"

            return f"{value:{format_str}}{indicator}{change_str}".strip()

        # --- –≠—Ç–∞–ø 7: –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –ª–∏–¥–µ—Ä–±–æ—Ä–¥–∞ ---
        leaderboard_df = pd.DataFrame()
        leaderboard_df['–†–∞–Ω–≥'] = metrics['Rank']
        leaderboard_df['–ú–æ–¥–µ–ª—å'] = metrics.index
        leaderboard_df['Trust Score'] = metrics['Trust_Score'].map(lambda x: f"{x:.3f}")
        leaderboard_df['Accuracy'] = metrics.apply(
            lambda row: format_with_indicator(row['Accuracy'], row['Accuracy_Change'], '.1%'),
            axis=1
        )
        leaderboard_df['Coverage'] = metrics['Comprehensiveness'].map(lambda x: f"{x:.0%}")
        leaderboard_df['Verbosity'] = metrics['Verbosity_Index'].map(lambda x: f"{x:.1%}")
        leaderboard_df['Avg Time'] = metrics['Avg_Time_ms'].map(lambda x: f"{x:,.0f} –º—Å")
        leaderboard_df['Runs'] = metrics['Total_Runs'].astype(int)

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–Ω–≥ –∫–∞–∫ –∏–Ω–¥–µ–∫—Å –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        leaderboard_df.set_index('–†–∞–Ω–≥', inplace=True)

        # --- –≠—Ç–∞–ø 8: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏—é ---
        self._save_history(metrics[['Trust_Score', 'Accuracy', 'Total_Runs']])

        return leaderboard_df

    def _load_history(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""
        if not self.history_path.exists():
            log.info("–§–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ '%s' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—å—Å—è –Ω–µ –±—É–¥–µ—Ç.", self.history_path.name)
            return pd.DataFrame()

        try:
            history_df = pd.read_json(self.history_path, orient='index')
            log.info("‚úÖ –§–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ '%s' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.", self.history_path.name)
            return history_df
        except Exception as e:
            log.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ %s: %s", self.history_path, e)
            return pd.DataFrame()

    def _save_history(self, metrics: pd.DataFrame):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ñ–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏."""
        history_data = metrics[['Trust_Score', 'Accuracy', 'Total_Runs']].copy()

        try:
            history_data.to_json(self.history_path, orient='index', indent=4)
            log.info("‚úÖ –§–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ '%s' –æ–±–Ω–æ–≤–ª–µ–Ω –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.", self.history_path.name)
        except Exception as e:
            log.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ %s: %s", self.history_path, e)

    def _get_best_cpu_name(self, cpu_info: Dict[str, Any], platform: str) -> str:
        """–í—ã–±–∏—Ä–∞–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞."""
        if not isinstance(cpu_info, dict):
            return "Unknown CPU (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)"

        if platform == 'Darwin':  # macOS
            fields_priority = ['cpu_brand', 'model_name', 'processor_name']
        elif platform == 'Linux':
            fields_priority = ['model_name', 'processor_name', 'cpu_brand']
        elif platform == 'Windows':
            fields_priority = ['cpu_model', 'processor_name', 'model_name']
        else:
            fields_priority = ['processor_name']

        # –ò—â–µ–º –ø–µ—Ä–≤–æ–µ –¥–æ—Å—Ç—É–ø–Ω–æ–µ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ
        for field in fields_priority:
            value = safe_get_dict(cpu_info, field, '').strip()
            if value and value not in ['i386', 'x86_64', 'Unknown', '']:
                return value

        # Fallback –∫ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        cores = safe_get_dict(cpu_info, 'physical_cores', 'Unknown')
        threads = safe_get_dict(cpu_info, 'logical_cores', 'Unknown')
        arch = safe_get_dict(cpu_info, 'real_architecture', safe_get_dict(cpu_info, 'processor_name', 'Unknown'))

        return f"Unknown CPU ({cores} cores, {threads} threads, {arch})"

    def _get_best_cpu_frequency(self, cpu_info: Dict[str, Any]) -> Optional[str]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —á–∞—Å—Ç–æ—Ç—É –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
        if not isinstance(cpu_info, dict):
            return None

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —á–∞—Å—Ç–æ—Ç—ã
        if 'cpu_frequency_hz' in cpu_info:
            freq_hz = safe_get_dict(cpu_info, 'cpu_frequency_hz', 0)
            if freq_hz > 1000000000:  # GHz
                return f"{freq_hz / 1000000000:.2f} GHz"
            elif freq_hz > 1000000:  # MHz
                return f"{freq_hz / 1000000:.0f} MHz"

        max_freq = safe_get_dict(cpu_info, 'max_frequency_mhz', 0)
        if max_freq:
            if max_freq >= 1000:
                return f"{max_freq / 1000:.2f} GHz (–º–∞–∫—Å.)"
            else:
                return f"{max_freq:.0f} MHz (–º–∞–∫—Å.)"

        curr_freq = safe_get_dict(cpu_info, 'current_frequency_mhz', 0)
        if curr_freq:
            if curr_freq >= 1000:
                return f"{curr_freq / 1000:.2f} GHz (—Ç–µ–∫—É—â–∞—è)"
            else:
                return f"{curr_freq:.0f} MHz (—Ç–µ–∫—É—â–∞—è)"

        cpu_mhz = safe_get_dict(cpu_info, 'cpu_mhz', 0)
        if cpu_mhz:
            if cpu_mhz >= 1000:
                return f"{cpu_mhz / 1000:.2f} GHz"
            else:
                return f"{cpu_mhz:.0f} MHz"

        return None

    def _generate_context_performance_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞—Ö."""
        if self.context_stress_results.empty:
            return ""

        df = self.context_stress_results.copy()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤–∞—Ä–µ–π
        if 'performance_metrics' in df.columns:
            perf_metrics = df['performance_metrics'].apply(pd.Series)
            df = pd.concat([df.drop(['performance_metrics'], axis=1), perf_metrics], axis=1)

        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        pivot = df.pivot_table(
            index=['model_name', 'context_k'],
            values=['is_correct', 'execution_time_ms', 'peak_ram_usage_mb'],
            aggfunc={
                'is_correct': 'mean',
                'execution_time_ms': 'mean',
                'peak_ram_usage_mb': 'mean'
            }
        ).sort_index()

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—ã–≤–æ–¥–∞
        pivot.rename(columns={
            'is_correct': 'Accuracy',
            'execution_time_ms': 'Avg Time (ms)',
            'peak_ram_usage_mb': 'Avg RAM (MB)'
        }, inplace=True)

        pivot['Accuracy'] = pivot['Accuracy'].map(lambda x: f"{x:.0%}")
        pivot['Avg Time (ms)'] = pivot['Avg Time (ms)'].map(lambda x: f"{x:,.0f}")
        pivot['Avg RAM (MB)'] = pivot['Avg RAM (MB)'].map(lambda x: f"{x:,.1f}")

        report_md = "## üß† –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª–∏–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n\n"
        report_md += "> _–≠—Ç–∞ —Ç–∞–±–ª–∏—Ü–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ –º–µ–Ω—è–µ—Ç—Å—è —Ç–æ—á–Ω–æ—Å—Ç—å –∏ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –º–æ–¥–µ–ª–∏ —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ò–¥–µ–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç 100% —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º —Ä–æ—Å—Ç–µ –≤—Ä–µ–º–µ–Ω–∏ –∏ RAM._\n\n"
        report_md += self._to_markdown_table(pivot.reset_index())
        return report_md

    def _generate_heatmap_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–±–ª–µ–º—ã '–ø–æ—Ç–µ—Ä—è–Ω–Ω–æ–π —Å–µ—Ä–µ–¥–∏–Ω—ã'."""
        if self.context_stress_results.empty:
            return ""

        df = self.context_stress_results.copy()

        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        heatmap = df.pivot_table(
            index=['model_name', 'depth_percent'],
            columns='context_k',
            values='is_correct',
            aggfunc='mean'
        )

        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        heatmap.fillna(-1, inplace=True)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–∏–º–≤–æ–ª—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        def to_emoji(score):
            if score == 1.0:
                return "‚úÖ"
            elif score == 0.0:
                return "‚ùå"
            elif score == -1:
                return "N/A"
            else:
                return "‚ö†Ô∏è"

        heatmap_emoji = heatmap.applymap(to_emoji)
        heatmap_emoji.columns = [f"{col}k" for col in heatmap_emoji.columns]

        report_md = "## üî• –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –≤–Ω–∏–º–∞–Ω–∏—è (Needle in a Haystack)\n\n"
        report_md += "> _–≠—Ç–∞ —Ç–∞–±–ª–∏—Ü–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞ –∫–∞–∫–æ–π –≥–ª—É–±–∏–Ω–µ –∏ –ø—Ä–∏ –∫–∞–∫–æ–º —Ä–∞–∑–º–µ—Ä–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª—å '—Ç–µ—Ä—è–µ—Ç' —Ñ–∞–∫—Ç. ‚úÖ = –ù–∞—à–ª–∞, ‚ùå = –ù–µ –Ω–∞—à–ª–∞, N/A = –¢–µ—Å—Ç –Ω–µ –∑–∞–ø—É—Å–∫–∞–ª—Å—è._\n\n"
        report_md += self._to_markdown_table(heatmap_emoji.reset_index())
        return report_md

    def generate_leaderboard_report(self) -> str:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –º–µ—Ç–æ–¥: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π.
        –£–±—Ä–∞–Ω—ã: —Å–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é, —Å–ª–æ–∂–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏.
        –î–æ–±–∞–≤–ª–µ–Ω–æ: –ø—Ä–æ—Å—Ç–∞—è —Å–≤–æ–¥–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å—é –∏ –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å—é.
        """
        if self.all_results.empty:
            return "# üèÜ –¢–∞–±–ª–∏—Ü–∞ –õ–∏–¥–µ—Ä–æ–≤\n\n–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        # # –û–¢–õ–ê–î–ö–ê: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        # exec_time_stats = self.all_results['execution_time_ms'].describe()
        # nan_count = self.all_results['execution_time_ms'].isna().sum()
        # zero_count = (self.all_results['execution_time_ms'] == 0).sum()
        #
        # log.info("=== –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –î–ê–ù–ù–´–• ===")
        # log.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ execution_time_ms:\n{exec_time_stats}")
        # log.info(f"NaN –∑–Ω–∞—á–µ–Ω–∏–π: {nan_count}")
        # log.info(f"–ù—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {zero_count}")
        # log.info(f"–í–∞–ª–∏–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {len(self.all_results) - nan_count - zero_count}")

        time_cols = [col for col in self.all_results.columns if 'time' in col.lower()]
        log.info("–ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º: %s", time_cols)

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç—á–µ—Ç–∞
        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
        report_md = f"# üèÜ –û—Ç—á–µ—Ç –ø–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é LLM –º–æ–¥–µ–ª–µ–π\n\n"
        report_md += f"*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {timestamp}*\n\n"

        # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ª–∏–¥–µ—Ä–æ–≤ (–∏—Å–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç—ã)
        main_results = self.all_results[self.all_results[
                                            'category'] != 't_context_stress'] if 'category' in self.all_results.columns else self.all_results

        if not main_results.empty:
            try:
                leaderboard_df = self._calculate_leaderboard(main_results)
                report_md += "## üèÜ –û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π\n\n"
                report_md += "> _–ú–æ–¥–µ–ª–∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω—ã –ø–æ Trust Score - —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ, —É—á–∏—Ç—ã–≤–∞—é—â–µ–π –∫–∞–∫ —Ç–æ—á–Ω–æ—Å—Ç—å, —Ç–∞–∫ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤._\n\n"
                report_md += self._to_markdown_table(leaderboard_df)
            except Exception as e:
                log.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–∞: {e}")
                report_md += "## üèÜ –û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π\n\n–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–∞–±–ª–∏—Ü—ã –ª–∏–¥–µ—Ä–æ–≤.\n"
        else:
            report_md += "## üèÜ –û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π\n\n–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –ª–∏–¥–µ—Ä–æ–≤.\n"

        report_md += "\n---\n"

        # –ù–û–í–û–ï: –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç—É—é —Å–≤–æ–¥–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (KISS)
        try:
            performance_report = self._generate_performance_summary()
            if performance_report:
                report_md += performance_report
                report_md += "\n---\n"
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤–æ–¥–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")

        # –ü–æ—Å–ª–µ —Å–µ–∫—Ü–∏–∏ "‚ö° –°–≤–æ–¥–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
        report_md += "\n---\n"

        # –ù–û–í–û–ï: –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–π—Ç–∏–Ω–≥ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
        try:
            local_providers_report = self._generate_local_providers_report()
            if local_providers_report:
                report_md += local_providers_report
                report_md += "\n---\n"
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–π—Ç–∏–Ω–≥–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤: {e}")

        # –û—Ç—á–µ—Ç—ã –ø–æ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∞–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        try:
            context_perf_report = self._generate_context_performance_report()
            if context_perf_report:
                report_md += context_perf_report
                report_md += "\n---\n"
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É: {e}")

        try:
            heatmap_report = self._generate_heatmap_report()
            if heatmap_report:
                report_md += heatmap_report
                report_md += "\n---\n"
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã: {e}")

        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        report_md += "## üìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n\n"
        if not main_results.empty:
            try:
                test_stats = main_results.groupby(['model_name', 'category'])['is_correct'].agg(['sum', 'count'])
                test_stats['Accuracy'] = (test_stats['sum'] / test_stats['count'])
                test_stats.sort_values(by=['model_name', 'Accuracy'], ascending=[True, False], inplace=True)
                test_stats.rename(columns={'sum': '–£—Å–ø–µ—à–Ω–æ', 'count': '–ü–æ–ø—ã—Ç–æ–∫'}, inplace=True)
                test_stats['Accuracy'] = test_stats['Accuracy'].map(lambda x: f"{x:.0%}")
                report_md += self._to_markdown_table(test_stats[['–ü–æ–ø—ã—Ç–æ–∫', '–£—Å–ø–µ—à–Ω–æ', 'Accuracy']].reset_index())
                report_md += "\n> _–≠—Ç–∞ —Ç–∞–±–ª–∏—Ü–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∏–ª—å–Ω—ã–µ –∏ —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –≤ —Ä–∞–∑—Ä–µ–∑–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π._\n"
            except Exception as e:
                log.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
                report_md += "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.\n"
        else:
            report_md += "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.\n"

        # –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        report_md += "\n---\n\n## üìã –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è\n\n"
        report_md += "**Trust Score** - –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –í–∏–ª—å—Å–æ–Ω–∞ (–Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞) –¥–ª—è –±–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–π –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ —É—Å–ø–µ—Ö–∞.\n\n"
        report_md += "**Accuracy** - –ø—Ä–æ—Å—Ç–∞—è –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤. –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: ‚ñ≤ —Ä–æ—Å—Ç, ‚ñº –ø–∞–¥–µ–Ω–∏–µ, ‚ñ¨ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å.\n\n"
        report_md += "**Coverage** - –¥–æ–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª—å —É—á–∞—Å—Ç–≤–æ–≤–∞–ª–∞.\n\n"
        report_md += "**Verbosity** - –¥–æ–ª—è thinking-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –æ—Ç –æ–±—â–µ–≥–æ –æ–±—ä–µ–º–∞ –≤—ã–≤–æ–¥–∞ –º–æ–¥–µ–ª–∏.\n\n"
        report_md += "**–°—Ä–µ–¥–Ω—è—è –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å** - —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö.\n\n"
        report_md += "**p95 –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å** - 95-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–∫–ª–∏–∫–∞ (95% –∑–∞–ø—Ä–æ—Å–æ–≤ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ).\n\n"
        report_md += "**QPS** - –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å (–∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É).\n\n"

        return report_md

    def _generate_performance_summary(self) -> str:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –º–µ—Ç–æ–¥: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Å—Ç—É—é —Å–≤–æ–¥–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ KISS-–ø—Ä–∏–Ω—Ü–∏–ø—É.
        """
        if self.all_results.empty:
            return ""

        # –§–∏–ª—å—Ç—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–±–µ–∑ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–æ–≤)
        main_results = self.all_results[self.all_results['category'] != 't_context_stress'] if 'category' in self.all_results.columns else self.all_results

        if main_results.empty:
            log.warning("–ù–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–æ–≤")
            return ""

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –ø–æ–ª–µ–π
        if 'execution_time_ms' not in main_results.columns:
            log.warning("–ü–æ–ª–µ 'execution_time_ms' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö")
            return ""

        # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN/None/–Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –≤—Ä–µ–º–µ–Ω–∏
        valid_results = main_results[
            (main_results['execution_time_ms'].notna()) &
            (main_results['execution_time_ms'] > 0)
            ].copy()

        if valid_results.empty:
            log.warning("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–≤—Å–µ NaN/None/0)")
            return ""

        log.info(f"–í–∞–ª–∏–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {len(valid_results)}")

        try:
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –º–æ–¥–µ–ª—è–º
            perf_summary = valid_results.groupby('model_name').agg({
                'execution_time_ms': [
                    'mean',
                    'count',
                    lambda x: np.percentile(x, 95) if len(x) > 0 else 0
                ]
            }).round(1)

            # –£–ø—Ä–æ—â–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏
            perf_summary.columns = ['avg_latency_ms', 'total_runs', 'p95_latency_ms']

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–ø—É—Å–∫–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å
            perf_summary['approx_qps'] = (1000 / perf_summary['avg_latency_ms']).round(2)

            # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
            summary_df = pd.DataFrame({
                '–ú–æ–¥–µ–ª—å': perf_summary.index,
                '–°—Ä–µ–¥–Ω—è—è –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–º—Å)': perf_summary['avg_latency_ms'].astype(int),
                'p95 –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–º—Å)': perf_summary['p95_latency_ms'].astype(int),
                '–ü—Ä–∏–º–µ—Ä–Ω. QPS': perf_summary['approx_qps'],
                '–í—Å–µ–≥–æ –∑–∞–ø—É—Å–∫–æ–≤': perf_summary['total_runs'].astype(int)
            })

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ p95 –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            summary_df = summary_df.sort_values('p95 –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–º—Å)').reset_index(drop=True)

            report_md = "## ‚ö° –°–≤–æ–¥–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n\n"
            report_md += f"> _–ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø–æ {len(summary_df)} –º–æ–¥–µ–ª—è–º. –ú–æ–¥–µ–ª–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ p95 –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏._\n\n"
            report_md += self._to_markdown_table(summary_df)

            return report_md

        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}", exc_info=True)
            return ""

    def _generate_local_providers_report(self) -> str:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –º–µ—Ç–æ–¥: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ model_details.provider –∏ hardware_tier.
        """
        if self.all_results.empty:
            return ""

        main_results = self.all_results[self.all_results['category'] != 't_context_stress'] if 'category' in self.all_results.columns else self.all_results

        if main_results.empty:
            return ""

        def get_local_provider(row) -> str:
            """
            –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä —Å —É—á–µ—Ç–æ–º model_details.provider –∏ hardware_tier.
            """
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            model_name = row.get('model_name', '').lower()
            hardware_tier = row.get('hardware_tier', '').lower()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º provider –∏–∑ model_details
            model_details = row.get('model_details', {})
            if isinstance(model_details, dict):
                provider_type = model_details.get('provider', '').lower()
            else:
                provider_type = ''

            # 1. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —è–≤–Ω—ã–π provider –∏–∑ model_details
            if provider_type == 'ollamaclient':
                return 'ollama'
            elif provider_type in ['janclient', 'localclient']:
                return 'jan'
            elif provider_type == 'lmstudioclient':
                return 'lmstudio'

            # 2. OpenAICompatibleClient –º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –ª–æ–∫–∞–ª—å–Ω—ã–º, –∏ API
            elif provider_type == 'openaicompatibleclient':
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º hardware_tier –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç–∏
                local_tiers = ['entry_level', 'mid_range', 'desktop_mac', 'high_end_mac', 'workstation_mac', 'workstation_cpu', 'mobile_cpu']

                if hardware_tier in local_tiers:
                    # –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API
                    if model_name.startswith('jan-'):
                        return 'jan'
                    elif any(model_name.startswith(prefix) for prefix in ['qwen', 'llama', 'gemma', 'phi', 'mistral']):
                        return 'ollama'
                    else:
                        return 'local'
                else:
                    # –í–Ω–µ—à–Ω–∏–π API
                    return 'api'

            # 3. –î—Ä—É–≥–∏–µ API –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
            elif provider_type in ['geminiclient', 'openai', 'anthropic']:
                return 'api'

            # 4. –†–µ–∑–µ—Ä–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø–æ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏ –∏ hardware_tier
            local_tiers = ['entry_level', 'mid_range', 'desktop_mac', 'high_end_mac', 'workstation_mac']

            if hardware_tier in local_tiers:
                # –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
                if model_name.startswith('jan-'):
                    return 'jan'
                elif ':' in model_name or any(prefix in model_name for prefix in ['qwen', 'llama', 'gemma', 'deepseek-r1:']):
                    return 'ollama'
                else:
                    return 'local'

            # 5. –Ø–≤–Ω–æ –≤–Ω–µ—à–Ω–∏–µ API (–ø–æ —Å–ª—ç—à–∞–º –∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º)
            api_patterns = ['google/', 'openai/', 'anthropic/', 'gemini-', 'deepseek/', 'tngtech/', 'meta-llama/', 'moonshotai/']
            if any(pattern in model_name for pattern in api_patterns):
                return 'api'

            return 'unknown'

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é
        main_results = main_results.copy()
        main_results['provider'] = main_results.apply(get_local_provider, axis=1)

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
        local_results = main_results[main_results['provider'].isin(['jan', 'ollama', 'lmstudio', 'local'])]

        if local_results.empty:
            log.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return ""

        log.info(f"–ù–∞–π–¥–µ–Ω–æ {len(local_results)} –∑–∞–ø–∏—Å–µ–π –æ—Ç –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤")

        try:
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
            model_agg = local_results.groupby(['provider', 'model_name']).agg({
                'is_correct': ['sum', 'count'],
                'execution_time_ms': ['mean', lambda x: np.percentile(x, 95)]
            }).round(1)

            model_agg.columns = ['successes', 'total_runs', 'avg_latency_ms', 'p95_latency_ms']
            model_agg = model_agg.reset_index()

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            model_agg['accuracy'] = model_agg['successes'] / model_agg['total_runs']
            model_agg['trust_score'] = model_agg.apply(
                lambda row: wilson_score_interval(int(row['successes']), int(row['total_runs']))[0],
                axis=1
            )
            model_agg['qps'] = (1000 / model_agg['avg_latency_ms']).round(2)

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ Trust Score
            model_agg = model_agg.sort_values(
                by=['trust_score', 'accuracy', 'avg_latency_ms'],
                ascending=[False, False, True]
            )

            # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
            local_table = pd.DataFrame({
                '–ü—Ä–æ–≤–∞–π–¥–µ—Ä': model_agg['provider'].str.upper(),
                '–ú–æ–¥–µ–ª—å': model_agg['model_name'],
                'Trust Score': model_agg['trust_score'].round(3),
                '–¢–æ—á–Ω–æ—Å—Ç—å': model_agg['accuracy'].apply(lambda x: f"{x:.1%}"),
                '–°—Ä–µ–¥–Ω—è—è –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–º—Å)': model_agg['avg_latency_ms'].astype(int),
                'p95 –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–º—Å)': model_agg['p95_latency_ms'].astype(int),
                'QPS': model_agg['qps'],
                '–ó–∞–ø—É—Å–∫–æ–≤': model_agg['total_runs'].astype(int)
            })

            report_md = "## üè† –õ–∏–¥–µ—Ä—ã –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤\n\n"
            report_md += f"> _–í—Å–µ {len(local_table)} –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ Trust Score. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ model_details.provider –∏ hardware_tier._\n\n"
            report_md += self._to_markdown_table(local_table.reset_index(drop=True))

            return report_md

        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–π—Ç–∏–Ω–≥–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤: {e}", exc_info=True)
            return ""



    def save_report_to_file(self, filename: Optional[str] = None) -> Path:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –≤ Markdown —Ñ–∞–π–ª."""
        if filename is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            hardware_suffix = f"_{safe_get_hardware_tier(self.hardware_tier)}" if safe_get_hardware_tier(
                self.hardware_tier) else ""
            filename = f"llm_benchmark_report{hardware_suffix}_{timestamp}.md"

        report_content = self.generate_leaderboard_report()
        report_path = self.results_dir.parent / filename

        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            log.info(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
            return report_path
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
            raise
