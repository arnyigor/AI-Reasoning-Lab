import time
import re
from pathlib import Path
import pandas as pd
import logging

log = logging.getLogger(__name__)


class Reporter:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—ã—Ä—ã–µ JSON-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.
    """

    def __init__(self, results_dir: Path):
        self.results_dir = results_dir
        self.all_results: pd.DataFrame = self._load_all_results()

    def _load_all_results(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ JSON —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏."""
        all_data = []
        json_files = sorted(list(self.results_dir.glob("*.json")))
        log.info("–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—Ç—á–µ—Ç–∞: %d", len(json_files))

        for json_file in json_files:
            try:
                data = pd.read_json(json_file)
                if not data.empty:
                    all_data.append(data)
            except Exception as e:
                log.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ %s: %s", json_file, e)

        if not all_data:
            log.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞.")
            return pd.DataFrame()

        combined_data = pd.concat(all_data, ignore_index=True)
        log.info("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: %d", len(combined_data))
        return combined_data

    def _to_markdown_table(self, df: pd.DataFrame) -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç DataFrame –≤ Markdown —Ç–∞–±–ª–∏—Ü—É."""
        if df.empty:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n"
        try:
            # fillna –ø–µ—Ä–µ–¥ to_markdown –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            return df.fillna("N/A").to_markdown() + "\n"
        except ImportError:
            log.error(
                "–î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Markdown-—Ç–∞–±–ª–∏—Ü —Ç—Ä–µ–±—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'tabulate'. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–µ: pip install tabulate")
            return "–û—à–∏–±–∫–∞: –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'tabulate' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.\n"

    def _calculate_verbosity(self, df: pd.DataFrame) -> pd.Series:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç '–∏–Ω–¥–µ–∫—Å –±–æ–ª—Ç–ª–∏–≤–æ—Å—Ç–∏' –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏."""

        def get_clean_len(text):
            # ... (—ç—Ç–∞ –≤–ª–æ–∂–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
            pattern = re.compile(
                r"\b–û–ë–†–ê–ë–û–¢–ê–ù–û\b:.*?\b–ì–õ–ê–°–ù–´–•\b:.*?\d+",
                re.DOTALL | re.IGNORECASE
            )
            match = pattern.search(text)
            return len(match.group(0)) if match else 0

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º DataFrame
        df['raw_len'] = df['llm_response'].str.len()
        df['clean_len'] = df['llm_response'].apply(get_clean_len)

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏
        grouped = df.groupby('model_name')

        # –°—á–∏—Ç–∞–µ–º —Å—É–º–º—ã –ø–æ –Ω—É–∂–Ω—ã–º –∫–æ–ª–æ–Ω–∫–∞–º
        sums = grouped[['raw_len', 'clean_len']].sum()

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å –±–æ–ª—Ç–ª–∏–≤–æ—Å—Ç–∏, –∏–∑–±–µ–≥–∞—è –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        # –≠—Ç–æ –±–æ–ª–µ–µ —á–∏—Ç–∞–µ–º—ã–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–±, —á–µ–º .apply —Å –ª—è–º–±–¥–æ–π
        model_verbosity = (sums['raw_len'] - sums['clean_len']) / sums['raw_len']
        model_verbosity = model_verbosity.fillna(0)  # –ó–∞–º–µ–Ω—è–µ–º NaN (–µ—Å–ª–∏ raw_len –±—ã–ª 0) –Ω–∞ 0

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏, —á—Ç–æ–±—ã –Ω–µ "–∑–∞–≥—Ä—è–∑–Ω—è—Ç—å" –æ—Å–Ω–æ–≤–Ω–æ–π DataFrame
        df.drop(columns=['raw_len', 'clean_len'], inplace=True)

        return model_verbosity

    def generate_leaderboard_report(
            self,
            confidence_threshold: int = 20
    ) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π, —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ—Ç—á–µ—Ç —Å —Ç–∞–±–ª–∏—Ü–µ–π –ª–∏–¥–µ—Ä–æ–≤
        –∏ –ø–æ–¥—Ä–æ–±–Ω—ã–º–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫.
        """
        if self.all_results.empty:
            return "# üèÜ –¢–∞–±–ª–∏—Ü–∞ –õ–∏–¥–µ—Ä–æ–≤\n\n–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        # --- –≠—Ç–∞–ø—ã 1-5: –†–∞—Å—á–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ---
        metrics = self.all_results.groupby('model_name').agg(
            Accuracy=('is_correct', 'mean'),
            Total_Runs=('is_correct', 'count')
        )
        metrics['Confidence_Mod'] = (metrics['Total_Runs'] / confidence_threshold).clip(upper=1.0)
        metrics['Reasoning_Score'] = metrics['Accuracy'] * metrics['Confidence_Mod']
        metrics.sort_values(by='Reasoning_Score', ascending=False, inplace=True)
        metrics.insert(0, '–†–∞–Ω–≥', range(1, len(metrics) + 1))
        metrics['Score'] = metrics['Reasoning_Score'].map(lambda x: f"{x:.3f}")
        metrics['Accuracy'] = metrics['Accuracy'].map(lambda x: f"{x:.1%}")
        metrics['Confidence'] = metrics['Confidence_Mod'].map(lambda x: f"{x:.0%}")
        metrics['Runs'] = metrics['Total_Runs']
        leaderboard_df = metrics[['–†–∞–Ω–≥', 'Score', 'Accuracy', 'Runs', 'Confidence']]
        leaderboard_df.index.name = "–ú–æ–¥–µ–ª—å"

        # --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Markdown –û—Ç—á–µ—Ç–∞ ---

        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
        report_md = f"# üèÜ –¢–∞–±–ª–∏—Ü–∞ –õ–∏–¥–µ—Ä–æ–≤ –ë–µ–Ω—á–º–∞—Ä–∫–∞\n\n"
        report_md += f"*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {timestamp}*\n\n"

        # --- –¢–∞–±–ª–∏—Ü–∞ –ª–∏–¥–µ—Ä–æ–≤ ---
        report_md += self._to_markdown_table(leaderboard_df)
        report_md += "\n---\n"

        report_md += "### üìñ –ö–∞–∫ —á–∏—Ç–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –ª–∏–¥–µ—Ä–æ–≤\n\n"
        report_md += "- **–†–∞–Ω–≥**: –ò—Ç–æ–≥–æ–≤–æ–µ –º–µ—Å—Ç–æ –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ.\n"
        report_md += "- **Score (–ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª)**: –ì–ª–∞–≤–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏. –û–Ω –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–∞–µ—Ç –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–æ—á–Ω—ã, –Ω–æ –∏ –ø—Ä–æ—à–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤, —á—Ç–æ–±—ã –º—ã –º–æ–≥–ª–∏ –¥–æ–≤–µ—Ä—è—Ç—å –∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫ `Accuracy * Confidence`.\n"
        report_md += "- **Accuracy (–¢–æ—á–Ω–æ—Å—Ç—å)**: –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤. –≠—Ç–æ –∫–ª—é—á–µ–≤–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å \"–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞\" –º–æ–¥–µ–ª–∏.\n"
        report_md += "- **Runs (–ó–∞–ø—É—Å–∫–∏)**: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–¥–∞—á, –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—å—é.\n"
        report_md += f"- **Confidence (–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)**: –ù–∞—Å–∫–æ–ª—å–∫–æ –º—ã –º–æ–∂–µ–º –¥–æ–≤–µ—Ä—è—Ç—å –ø–æ–∫–∞–∑–∞—Ç–µ–ª—é —Ç–æ—á–Ω–æ—Å—Ç–∏. –≠—Ç–æ—Ç –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä \"—à—Ç—Ä–∞—Ñ—É–µ—Ç\" –º–æ–¥–µ–ª–∏ –∑–∞ –º–∞–ª–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤. –û–Ω –¥–æ—Å—Ç–∏–≥–∞–µ—Ç 100% –ø—Ä–∏ **{confidence_threshold}** –∏ –±–æ–ª–µ–µ –∑–∞–ø—É—Å–∫–∞—Ö.\n"
        report_md += "\n\n"

        # --- –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ—Å—Ç–∞–º ---
        report_md += "## üìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ—Å—Ç–∞–º\n\n"
        test_stats = self.all_results.groupby(['model_name', 'category'])['is_correct'].agg(['count', 'sum'])
        test_stats['Accuracy'] = (test_stats['sum'] / test_stats['count'])
        test_stats.columns = ['–ü–æ–ø—ã—Ç–æ–∫', '–£—Å–ø–µ—à–Ω–æ', '–¢–æ—á–Ω–æ—Å—Ç—å']
        test_stats['–¢–æ—á–Ω–æ—Å—Ç—å'] = test_stats['–¢–æ—á–Ω–æ—Å—Ç—å'].map(lambda x: f"{x:.0%}")
        report_md += self._to_markdown_table(test_stats)
        report_md += "\n"

        # >>>>> –ù–ê–ß–ê–õ–û –ò–ó–ú–ï–ù–ï–ù–ò–ô: –û–ë–™–Ø–°–ù–ï–ù–ò–ï –î–ï–¢–ê–õ–¨–ù–û–ô –°–¢–ê–¢–ò–°–¢–ò–ö–ò <<<<<
        report_md += "### üìñ –ö–∞–∫ —á–∏—Ç–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n\n"
        report_md += "–≠—Ç–∞ —Ç–∞–±–ª–∏—Ü–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç \"—Å–∏–ª—å–Ω—ã–µ\" –∏ \"—Å–ª–∞–±—ã–µ\" —Å—Ç–æ—Ä–æ–Ω—ã –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏, —Ä–∞—Å–∫—Ä—ã–≤–∞—è –µ–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –∫–∞–∂–¥–æ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–µ—Å—Ç–æ–≤.\n\n"
        report_md += "- **–ö–∞—Ç–µ–≥–æ—Ä–∏—è**: –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞–±–æ—Ä–∞ —Ç–µ—Å—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `t01_simple_logic`, `t03_code_gen`).\n"
        report_md += "- **–ü–æ–ø—ã—Ç–æ–∫**: –°–∫–æ–ª—å–∫–æ –∑–∞–¥–∞—á –∏–∑ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –±—ã–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–æ –º–æ–¥–µ–ª–∏.\n"
        report_md += "- **–£—Å–ø–µ—à–Ω–æ**: –°–∫–æ–ª—å–∫–æ –∏–∑ —ç—Ç–∏—Ö –∑–∞–¥–∞—á –º–æ–¥–µ–ª—å —Ä–µ—à–∏–ª–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ.\n"
        report_md += "- **–¢–æ—á–Ω–æ—Å—Ç—å**: –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞ –≤ –¥–∞–Ω–Ω–æ–π, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.\n"
        report_md += "\n\n"
        # >>>>> –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–ô <<<<<

        # --- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (–±–µ–∑ –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Ä–µ–π—Ç–∏–Ω–≥) ---
        report_md += "## ‚öôÔ∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏\n\n"
        verbosity = self._calculate_verbosity(self.all_results)
        verbosity.name = "Verbosity_Index"
        tech_metrics = self.all_results.groupby('model_name').agg(
            Avg_Time_ms=('execution_time_ms', 'mean')
        )
        tech_metrics = pd.concat([tech_metrics, verbosity], axis=1)
        tech_metrics['Avg_Time_ms'] = tech_metrics['Avg_Time_ms'].map(lambda x: f"{x:,.0f} –º—Å")
        tech_metrics['Verbosity_Index'] = tech_metrics['Verbosity_Index'].map(lambda x: f"{x:.1%}")
        report_md += self._to_markdown_table(tech_metrics)
        report_md += "\n"

        report_md += "### üìñ –ö–∞–∫ —á–∏—Ç–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏\n\n"
        report_md += "–≠—Ç–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç –Ω–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞, –∞ \"–ø–æ–≤–µ–¥–µ–Ω–∏–µ\" –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏. –û–Ω–∏ –Ω–µ –≤–ª–∏—è—é—Ç –Ω–∞ `Score`, –Ω–æ –≤–∞–∂–Ω—ã –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É.\n\n"
        report_md += "- **Avg_Time_ms (–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è)**: –°–∫–æ–ª—å–∫–æ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥ –≤ —Å—Ä–µ–¥–Ω–µ–º —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞—à–µ–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–∏.\n"
        report_md += "- **Verbosity Index (–ò–Ω–¥–µ–∫—Å –ë–æ–ª—Ç–ª–∏–≤–æ—Å—Ç–∏)**: –î–æ–ª—è –æ—Ç–≤–µ—Ç–∞, –Ω–µ —è–≤–ª—è—é—â–∞—è—Å—è –ø—Ä—è–º—ã–º —Ä–µ—à–µ–Ω–∏–µ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤—Å–ª—É—Ö, \"–º—É—Å–æ—Ä–Ω—ã–µ\" —Ç–æ–∫–µ–Ω—ã). `0%` ‚Äî –∏–¥–µ–∞–ª—å–Ω–æ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç, `90%` ‚Äî –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ 90% —Ç–µ–∫—Å—Ç–∞ –≤ –æ—Ç–≤–µ—Ç–µ —è–≤–ª—è–µ—Ç—Å—è \"—à—É–º–æ–º\", –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞—Ç—å.\n"

        return report_md
