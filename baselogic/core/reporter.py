import time
from pathlib import Path
import pandas as pd

class Reporter:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—ã—Ä—ã–µ JSON-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.
    """

    def __init__(self, results_dir: Path):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Reporter.

        Args:
            results_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Å—ã—Ä—ã–º–∏ JSON-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.
        """
        self.results_dir = results_dir
        # _load_all_results —Ç–µ–ø–µ—Ä—å –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ generate_markdown_report,
        # —á—Ç–æ–±—ã –≤—ã–≤–æ–¥ print() –Ω–µ –ø–æ—è–≤–ª—è–ª—Å—è –ø—Ä–∏ –ø—Ä–æ—Å—Ç–æ–º —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞.
        self.all_results: pd.DataFrame = pd.DataFrame()

    def _load_all_results(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ JSON —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏."""
        all_data = []
        json_files = sorted(list(self.results_dir.glob("*.json"))) # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞

        print(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(json_files)}")

        for json_file in json_files:
            try:
                data = pd.read_json(json_file)
                if data.empty:
                    print(f"–ü—Ä–æ–ø—É—â–µ–Ω –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª: {json_file.name}")
                    continue

                # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï 1: –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö ---
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É, —á—Ç–æ–±—ã –∑–Ω–∞—Ç—å, –∏–∑ –∫–∞–∫–æ–≥–æ —Ñ–∞–π–ª–∞ –ø—Ä–∏—à–ª–∞ –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞.
                # –≠—Ç–æ –∫–ª—é—á –∫ –ø–æ–¥—Å—á–µ—Ç—É –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø—É—Å–∫–æ–≤.
                data['source_file'] = json_file.name

                print(f"–ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {json_file.name}, –∑–∞–ø–∏—Å–µ–π: {len(data)}")
                all_data.append(data)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {json_file}: {e}")
                continue

        if not all_data:
            print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
            return pd.DataFrame()

        combined_data = pd.concat(all_data, ignore_index=True)
        print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(combined_data)}")
        return combined_data

    def generate_markdown_report(self) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown."""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞
        self.all_results = self._load_all_results()

        if self.all_results.empty:
            return "# –û—Ç—á–µ—Ç –æ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏\n\n–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï 2: –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—É—Å–∫–æ–≤ ---
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏ –∏ —Å—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö 'source_file' –¥–ª—è –∫–∞–∂–¥–æ–π.
        # .nunique() - —ç—Ç–æ "number of unique", –∏–¥–µ–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏.
        runs_count = self.all_results.groupby('model_name')['source_file'].nunique()
        runs_count.name = "–ó–∞–ø—É—Å–∫–æ–≤" # –î–∞–µ–º –∏–º—è —Å–µ—Ä–∏–∏, —á—Ç–æ–±—ã –æ–Ω–æ —Å—Ç–∞–ª–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –∫–æ–ª–æ–Ω–∫–∏

        # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ % –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        summary = self.all_results.groupby(['model_name', 'category'])['is_correct'].mean().unstack()
        summary['Overall'] = self.all_results.groupby('model_name')['is_correct'].mean()

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        summary_percent = summary.map(lambda x: f"{x:.0%}" if pd.notna(x) else "N/A")

        # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï 3: –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –∑–∞–ø—É—Å–∫–∞–º–∏ –≤ —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É ---
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º pd.concat –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø–æ –∏–Ω–¥–µ–∫—Å—É (model_name)
        summary_with_runs = pd.concat([runs_count, summary_percent], axis=1)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        report_md = "# üìä –û—Ç—á–µ—Ç –æ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ LLM\n\n"
        report_md += "## –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (% –≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤)\n\n"
        report_md += self._to_markdown_table(summary_with_runs)
        report_md += "\n\n"

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        report_md += "## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–º—Å)\n\n"
        time_stats = self.all_results.groupby('model_name')['execution_time_ms'].agg(['mean', 'min', 'max'])
        time_stats = time_stats.round(0).astype(int)
        time_stats.columns = ['–°—Ä–µ–¥–Ω–µ–µ', '–ú–∏–Ω', '–ú–∞–∫—Å']
        report_md += self._to_markdown_table(time_stats)
        report_md += "\n\n"

        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–µ—Å—Ç–∞–º
        report_md += "## –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ—Å—Ç–∞–º\n\n"
        test_stats = self.all_results.groupby(['model_name', 'category'])['is_correct'].agg(['count', 'sum'])

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ª—é –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        test_stats['–î–æ–ª—è'] = (test_stats['sum'] / test_stats['count']).map(lambda x: f"{x:.0%}")
        test_stats.columns = ['–í—Å–µ–≥–æ –ø–æ–ø—ã—Ç–æ–∫', '–ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö', '–î–æ–ª—è']

        report_md += self._to_markdown_table(test_stats)

        return report_md

    def _to_markdown_table(self, df: pd.DataFrame) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç DataFrame –≤ Markdown —Ç–∞–±–ª–∏—Ü—É."""
        if df.empty:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö\n"

        # –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω—ã–π 'N/A' –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        df_display = df.fillna('N/A')

        lines = []

        if isinstance(df_display.index, pd.MultiIndex):
            headers = list(df_display.index.names) + list(df_display.columns)
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –∏–Ω–¥–µ–∫—Å–∞, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å, –∏–ª–∏ 'Model' –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            index_name = df_display.index.name if df_display.index.name else 'Model'
            headers = [index_name] + list(df_display.columns)

        lines.append("| " + " | ".join(str(h) for h in headers) + " |")
        lines.append("| " + " | ".join(["---"] * len(headers)) + " |")

        for idx, row in df_display.iterrows():
            if isinstance(idx, tuple):
                row_values = [str(i) for i in idx] + [str(v) for v in row.values]
            else:
                row_values = [str(idx)] + [str(v) for v in row.values]
            lines.append("| " + " | ".join(row_values) + " |")

        return "\n".join(lines) + "\n"

    def generate_advanced_leaderboard(
            self,
            accuracy_weight: float = 0.7,
            speed_weight: float = 0.3,
            confidence_threshold: int = 10
    ) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é —Ç–∞–±–ª–∏—Ü—É –ª–∏–¥–µ—Ä–æ–≤ —Å –∫–æ–º–ø–æ–∑–∏—Ç–Ω—ã–º –±–∞–ª–ª–æ–º.

        –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å, —Å–∫–æ—Ä–æ—Å—Ç—å –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—É—Å–∫–æ–≤ (–¥–æ–≤–µ—Ä–∏–µ).

        Args:
            accuracy_weight (float): –í–µ—Å —Ç–æ—á–Ω–æ—Å—Ç–∏ –≤ –∏—Ç–æ–≥–æ–≤–æ–º –±–∞–ª–ª–µ.
            speed_weight (float): –í–µ—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –≤ –∏—Ç–æ–≥–æ–≤–æ–º –±–∞–ª–ª–µ.
            confidence_threshold (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—É—Å–∫–æ–≤, –ø–æ—Å–ª–µ –∫–æ—Ç–æ—Ä–æ–≥–æ
                                        —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –º–æ–∂–Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –¥–æ–≤–µ—Ä—è—Ç—å (—à—Ç—Ä–∞—Ñ = 0).
        Returns:
            str: –¢–µ–∫—Å—Ç —Ç–∞–±–ª–∏—Ü—ã –ª–∏–¥–µ—Ä–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.
        """
        if self.all_results.empty:
            self.all_results = self._load_all_results()

        if self.all_results.empty:
            return "# üèÜ –¢–∞–±–ª–∏—Ü–∞ –õ–∏–¥–µ—Ä–æ–≤\n\n–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        # 1. –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics = self.all_results.groupby('model_name').agg(
            Accuracy=('is_correct', 'mean'),
            Avg_Time_ms=('execution_time_ms', 'mean'),
            Runs=('source_file', 'nunique')
        )

        # 2. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ (0-1, –≥–¥–µ 1 - –ª—É—á—à–µ)
        metrics['norm_accuracy'] = metrics['Accuracy']
        min_time = metrics['Avg_Time_ms'].min()
        max_time = metrics['Avg_Time_ms'].max()
        if max_time == min_time:
            metrics['norm_speed'] = 0.5
        else:
            metrics['norm_speed'] = (max_time - metrics['Avg_Time_ms']) / (max_time - min_time)

        # 3. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –±–∞–∑–æ–≤—ã–π –±–∞–ª–ª (—Ç–æ—á–Ω–æ—Å—Ç—å + —Å–∫–æ—Ä–æ—Å—Ç—å)
        metrics['Base_Score'] = (accuracy_weight * metrics['norm_accuracy'] +
                                 speed_weight * metrics['norm_speed'])

        # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï: –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–æ–≤–µ—Ä–∏—è –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –±–∞–ª–ª ---
        metrics['Confidence'] = (metrics['Runs'] / confidence_threshold).clip(upper=1.0)
        metrics['Final_Score'] = metrics['Base_Score'] * metrics['Confidence']

        # 4. –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É –±–∞–ª–ª—É
        metrics.sort_values(by='Final_Score', ascending=False, inplace=True)
        metrics.insert(0, '–†–∞–Ω–≥', range(1, len(metrics) + 1))

        # 5. –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è –≤—ã–≤–æ–¥–∞
        metrics['Score'] = metrics['Final_Score'].map(lambda x: f"{x:.3f}")
        metrics['Accuracy'] = metrics['Accuracy'].map(lambda x: f"{x:.1%}")
        metrics['Avg_Time_ms'] = metrics['Avg_Time_ms'].map(lambda x: f"{x:,.0f} –º—Å")
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–æ–≤–µ—Ä–∏—è –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
        metrics['Confidence_Mod'] = metrics['Confidence'].map(lambda x: f"{x:.0%}")

        # 6. –í—ã–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        leaderboard_df = metrics[['–†–∞–Ω–≥', 'Score', 'Accuracy', 'Avg_Time_ms', 'Runs', 'Confidence_Mod']]
        leaderboard_df.index.name = "–ú–æ–¥–µ–ª—å"

        # 7. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Markdown —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º
        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
        leaderboard_md = f"# üèÜ –¢–∞–±–ª–∏—Ü–∞ –õ–∏–¥–µ—Ä–æ–≤\n\n"
        leaderboard_md += f"*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {timestamp}*\n\n"
        leaderboard_md += self._to_markdown_table(leaderboard_df)
        leaderboard_md += "\n---\n"
        leaderboard_md += "### –ö–∞–∫ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –±–∞–ª–ª (Score)\n\n"
        leaderboard_md += "–ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª —É—á–∏—Ç—ã–≤–∞–µ—Ç –¢–æ—á–Ω–æ—Å—Ç—å, –°–∫–æ—Ä–æ—Å—Ç—å –∏ –î–æ–≤–µ—Ä–∏–µ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —á–∏—Å–ª–∞ –∑–∞–ø—É—Å–∫–æ–≤).\n"
        leaderboard_md += f"`Score = ({accuracy_weight} * –¢–æ—á–Ω–æ—Å—Ç—å + {speed_weight} * –°–∫–æ—Ä–æ—Å—Ç—å) * –ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä_–î–æ–≤–µ—Ä–∏—è`\n\n"
        leaderboard_md += f"> **–ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä –î–æ–≤–µ—Ä–∏—è** ‚Äî —ç—Ç–æ —à—Ç—Ä–∞—Ñ –∑–∞ –º–∞–ª–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—É—Å–∫–æ–≤. –û–Ω —Ä–∞–≤–µ–Ω 100% –ø—Ä–∏ {confidence_threshold} –∏ –±–æ–ª–µ–µ –∑–∞–ø—É—Å–∫–∞—Ö."

        return leaderboard_md

