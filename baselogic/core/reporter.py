import logging
import math
import re
import time
from pathlib import Path
from typing import Tuple

import pandas as pd

log = logging.getLogger(__name__)


def wilson_score_interval(
        successes: int,
        total: int,
        confidence: float = 0.95
) -> Tuple[float, float]:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –£–∏–ª—Å–æ–Ω–∞ –¥–ª—è –±–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–π –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏.
    """
    if total == 0:
        return 0.0, 1.0
    z = 1.959963984540054
    p_hat = float(successes) / total
    part1 = p_hat + (z * z) / (2 * total)
    part2 = z * math.sqrt((p_hat * (1 - p_hat)) / total + (z * z) / (4 * total * total))
    denominator = 1 + (z * z) / total
    lower_bound = (part1 - part2) / denominator
    upper_bound = (part1 + part2) / denominator
    return lower_bound, upper_bound


class Reporter:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—ã—Ä—ã–µ JSON-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∏—Ö —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π, —Å–∞–º–æ–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–µ–º—ã–π –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.
    """

    def __init__(self, results_dir: Path):
        self.results_dir = results_dir
        self.history_path = self.results_dir.parent / "history.json"
        self.all_results: pd.DataFrame = self._load_all_results()

    def _load_all_results(self) -> pd.DataFrame:
        # ... (–≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        all_data = []
        json_files = sorted(list(self.results_dir.glob("*.json")))
        log.info("–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—Ç—á–µ—Ç–∞: %d", len(json_files))

        for json_file in json_files:
            try:
                data = pd.read_json(json_file)
                if not data.empty:
                    all_data.append(data)
            except Exception as e:
                log.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ %s: %s", json_file, e)

        if not all_data:
            log.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞.")
            return pd.DataFrame()

        combined_data = pd.concat(all_data, ignore_index=True)
        log.info("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: %d", len(combined_data))
        return combined_data

    def _load_history(self) -> pd.DataFrame:
        # ... (–≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        if not self.history_path.exists():
            log.info("–§–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ '%s' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—å—Å—è –Ω–µ –±—É–¥–µ—Ç.", self.history_path.name)
            return pd.DataFrame()
        try:
            history_df = pd.read_json(self.history_path, orient='index')
            log.info("‚úÖ –§–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ '%s' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.", self.history_path.name)
            return history_df
        except Exception as e:
            log.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ %s: %s", self.history_path, e)
            return pd.DataFrame()

    def _save_history(self, metrics: pd.DataFrame):
        # ... (–≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        history_data = metrics[['Trust_Score', 'Accuracy', 'Total_Runs']].copy()
        try:
            history_data.to_json(self.history_path, orient='index', indent=4)
            log.info("‚úÖ –§–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ '%s' –æ–±–Ω–æ–≤–ª–µ–Ω –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.", self.history_path.name)
        except Exception as e:
            log.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ %s: %s", self.history_path, e)

    def _to_markdown_table(self, df: pd.DataFrame) -> str:
        # ... (–≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        if df.empty:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n"
        try:
            return df.fillna("N/A").to_markdown() + "\n"
        except ImportError:
            log.error("–î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Markdown-—Ç–∞–±–ª–∏—Ü —Ç—Ä–µ–±—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'tabulate'. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–µ: pip install tabulate")
            return "–û—à–∏–±–∫–∞: –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'tabulate' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.\n"

    def _calculate_verbosity(self, df: pd.DataFrame) -> pd.Series:
        # ... (–≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        def get_clean_len(text: str) -> int:
            if not isinstance(text, str): return 0
            pattern = re.compile(r"\b–û–ë–†–ê–ë–û–¢–ê–ù–û\b.*?\b–ì–õ–ê–°–ù–´–•\b.*?\d+", re.DOTALL | re.IGNORECASE)
            match = pattern.search(text)
            return len(match.group(0)) if match else 0
        df['raw_len'] = df['llm_response'].str.len().fillna(0)
        df['clean_len'] = df['llm_response'].apply(get_clean_len)
        grouped = df.groupby('model_name')
        sums = grouped[['raw_len', 'clean_len']].sum()
        model_verbosity = (sums['raw_len'] - sums['clean_len']) / sums['raw_len']
        model_verbosity = model_verbosity.fillna(0)
        df.drop(columns=['raw_len', 'clean_len'], inplace=True)
        return model_verbosity

    def generate_leaderboard_report(self) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π, —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ—Ç—á–µ—Ç —Å —Ç–∞–±–ª–∏—Ü–µ–π –ª–∏–¥–µ—Ä–æ–≤,
        –ø–æ–¥—Ä–æ–±–Ω—ã–º–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏ –∏ –¥–∏–Ω–∞–º–∏–∫–æ–π –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫.
        """
        if self.all_results.empty:
            return "# üèÜ –¢–∞–±–ª–∏—Ü–∞ –õ–∏–¥–µ—Ä–æ–≤\n\n–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        # --- –≠—Ç–∞–ø—ã 1-3 (—Ä–∞—Å—á–µ—Ç—ã) –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ---
        metrics = self.all_results.groupby('model_name').agg(
            Successes=('is_correct', 'sum'),
            Total_Runs=('is_correct', 'count'),
            Avg_Time_ms=('execution_time_ms', 'mean')
        )
        verbosity = self._calculate_verbosity(self.all_results)
        verbosity.name = "Verbosity_Index"
        metrics = pd.concat([metrics, verbosity], axis=1)
        metrics['Accuracy'] = (metrics['Successes'] / metrics['Total_Runs']).fillna(0)
        metrics['Trust_Score'] = metrics.apply(
            lambda row: wilson_score_interval(int(row['Successes']), int(row['Total_Runs']))[0],
            axis=1
        )
        history_df = self._load_history()
        metrics['Accuracy_Change'] = 0.0
        if not history_df.empty:
            metrics = metrics.join(history_df.add_suffix('_prev'))
            metrics['Accuracy_Change'] = (metrics['Accuracy'] - metrics['Accuracy_prev']).fillna(0)

        # --- –≠—Ç–∞–ø 4: –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –∏ –¥–µ–ª—å—Ç–æ–π ---

        # >>>>> –ò–ó–ú–ï–ù–ï–ù–ò–ï 1: –û–±–Ω–æ–≤–ª—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è <<<<<
        def format_with_indicator(value, change, format_str):
            """
            –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ, –¥–æ–±–∞–≤–ª—è–µ—Ç —ç–º–æ–¥–∑–∏-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∏ –≤–µ–ª–∏—á–∏–Ω—É –∏–∑–º–µ–Ω–µ–Ω–∏—è.
            """
            indicator = ""
            change_str = ""
            threshold = 0.001 # 0.1%

            if change > threshold:
                indicator = " ‚ñ≤"
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–µ–ª—å—Ç—É —Å–æ –∑–Ω–∞–∫–æ–º '+' –∏ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
                change_str = f" (+{change:.1%})"
            elif change < -threshold:
                indicator = " ‚ñº"
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–µ–ª—å—Ç—É —Å–æ –∑–Ω–∞–∫–æ–º '-' (–æ–Ω —Å—Ç–∞–≤–∏—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
                change_str = f" ({change:.1%})"
            elif 'Accuracy_prev' in metrics.columns:
                indicator = " ‚ñ¨"

            return f"{value:{format_str}}{indicator}{change_str}"

        metrics.sort_values(by='Trust_Score', ascending=False, inplace=True)
        metrics.insert(0, '–†–∞–Ω–≥', range(1, len(metrics) + 1))

        leaderboard_df = pd.DataFrame()
        leaderboard_df['–†–∞–Ω–≥'] = metrics['–†–∞–Ω–≥']
        leaderboard_df['–ú–æ–¥–µ–ª—å'] = metrics.index
        leaderboard_df['Trust Score'] = metrics['Trust_Score'].map(lambda x: f"{x:.3f}")
        leaderboard_df['Accuracy'] = metrics.apply(lambda row: format_with_indicator(row['Accuracy'], row['Accuracy_Change'], '.1%'), axis=1)
        leaderboard_df['Verbosity'] = metrics['Verbosity_Index'].map(lambda x: f"{x:.1%}")
        leaderboard_df['Avg Time'] = metrics['Avg_Time_ms'].map(lambda x: f"{x:,.0f} –º—Å")
        leaderboard_df['Runs'] = metrics['Total_Runs']
        leaderboard_df.set_index('–†–∞–Ω–≥', inplace=True)

        self._save_history(metrics)

        # --- –≠—Ç–∞–ø 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Markdown –û—Ç—á–µ—Ç–∞ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –ø–æ—è—Å–Ω–µ–Ω–∏—è–º–∏ ---
        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
        report_md = f"# üèÜ –¢–∞–±–ª–∏—Ü–∞ –õ–∏–¥–µ—Ä–æ–≤ –ë–µ–Ω—á–º–∞—Ä–∫–∞\n\n"
        report_md += f"*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {timestamp}*\n\n"
        report_md += self._to_markdown_table(leaderboard_df)
        report_md += "\n---\n"

        report_md += "## üéØ –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è\n\n"
        report_md += "–†–µ–π—Ç–∏–Ω–≥ —Å—Ç—Ä–æ–∏—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ **Trust Score** ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–¥–µ–∂–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ, –∫–æ—Ç–æ—Ä–∞—è —É—á–∏—Ç—ã–≤–∞–µ—Ç –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–æ—á–Ω–æ—Å—Ç—å, –Ω–æ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –º–æ–¥–µ–ª–∏, –ø—Ä–æ—à–µ–¥—à–∏–µ —Ä–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø—ã—Ç–∞–Ω–∏–π.\n\n"
        report_md += "**Trust Score** ‚Äî —ç—Ç–æ –Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ 95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –£–∏–ª—Å–æ–Ω–∞. –ü—Ä–æ—â–µ –≥–æ–≤–æ—Ä—è, —ç—Ç–æ **–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ –æ–∂–∏–¥–∞—Ç—å –æ—Ç –º–æ–¥–µ–ª–∏ —Å 95% —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é**.\n\n"
        report_md += "> _–ü—Ä–∏–º–µ—Ä: –ú–æ–¥–µ–ª—å —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é 100% –Ω–∞ 2 —Ç–µ—Å—Ç–∞—Ö –±—É–¥–µ—Ç –∏–º–µ—Ç—å –Ω–∏–∑–∫–∏–π Trust Score (~0.206), –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –º–æ–¥–µ–ª—å —Å 90% —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ 100 —Ç–µ—Å—Ç–∞—Ö –±—É–¥–µ—Ç –∏–º–µ—Ç—å –≤—ã—Å–æ–∫–∏–π Trust Score (~0.825), —á—Ç–æ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ –æ—Ç—Ä–∞–∂–∞–µ—Ç –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –µ–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤._\n\n"

        # >>>>> –ò–ó–ú–ï–ù–ï–ù–ò–ï 2: –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ—è—Å–Ω–µ–Ω–∏—è <<<<<
        report_md += "### üìñ –ö–∞–∫ —á–∏—Ç–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –ª–∏–¥–µ—Ä–æ–≤\n\n"
        report_md += "- **–†–∞–Ω–≥**: –ò—Ç–æ–≥–æ–≤–æ–µ –º–µ—Å—Ç–æ –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ (—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ `Trust Score`).\n"
        report_md += "- **–ú–æ–¥–µ–ª—å**: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ—Å—Ç–∏—Ä—É–µ–º–æ–π LLM.\n"
        report_md += "- **Trust Score**: **–ì–ª–∞–≤–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è.** –ß–µ–º –≤—ã—à–µ, —Ç–µ–º –ª—É—á—à–µ.\n"
        report_md += "- **Accuracy**: –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤. –ü–æ–ª–µ–∑–µ–Ω –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –Ω–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è.\n"
        report_md += "- **–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã `‚ñ≤ ‚ñº ‚ñ¨`**: –ü–æ–∫–∞–∑—ã–≤–∞—é—Ç –¥–∏–Ω–∞–º–∏–∫—É —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –æ—Ç—á–µ—Ç–æ–º. –í —Å–∫–æ–±–∫–∞—Ö —É–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è **–∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ** (–Ω–∞–ø—Ä–∏–º–µ—Ä, `+5.1%`).\n\n"
        report_md += "**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–ù–ï –≤–ª–∏—è—é—Ç –Ω–∞ —Ä–∞–Ω–≥):**\n\n"
        report_md += "- **Verbosity**: \"–ò–Ω–¥–µ–∫—Å –±–æ–ª—Ç–ª–∏–≤–æ—Å—Ç–∏\" ‚Äî –¥–æ–ª—è \"—à—É–º–∞\" –≤ –æ—Ç–≤–µ—Ç–µ –º–æ–¥–µ–ª–∏. `0%` ‚Äî –∏–¥–µ–∞–ª—å–Ω–æ.\n"
        report_md += "- **Avg Time**: –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö.\n"
        report_md += "- **Runs**: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–¥–∞—á, –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—å—é.\n"

        report_md += "\n## üìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n\n"
        test_stats = self.all_results.groupby(['model_name', 'category'])['is_correct'].agg(['sum', 'count'])
        test_stats['Accuracy'] = (test_stats['sum'] / test_stats['count'])
        test_stats.sort_values(by=['model_name', 'Accuracy'], ascending=[True, False], inplace=True)
        test_stats.rename(columns={'sum': '–£—Å–ø–µ—à–Ω–æ', 'count': '–ü–æ–ø—ã—Ç–æ–∫'}, inplace=True)
        test_stats['Accuracy'] = test_stats['Accuracy'].map(lambda x: f"{x:.0%}")
        report_md += self._to_markdown_table(test_stats[['–ü–æ–ø—ã—Ç–æ–∫', '–£—Å–ø–µ—à–Ω–æ', 'Accuracy']])
        report_md += "\n> _–≠—Ç–∞ —Ç–∞–±–ª–∏—Ü–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∏–ª—å–Ω—ã–µ –∏ —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –≤ —Ä–∞–∑—Ä–µ–∑–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π._"

        return report_md