import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import pandas as pd
import numpy as np


class AdvancedReporter:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ª–∏–¥–µ—Ä–±–æ—Ä–¥–æ–≤
    –∏ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π.
    """

    def __init__(self, results_dir: Path):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç AdvancedReporter.

        Args:
            results_dir: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å JSON-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        self.results_dir = results_dir
        self.all_results: pd.DataFrame = pd.DataFrame()
        self.model_details_extracted: bool = False

    def _load_all_results(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ JSON —Ñ–∞–π–ª—ã –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ—Ç–∞–ª–∏ –º–æ–¥–µ–ª–µ–π."""
        all_data = []
        json_files = sorted(list(self.results_dir.glob("*.json")))

        print(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(json_files)}")

        for json_file in json_files:
            try:
                data = pd.read_json(json_file)
                if data.empty:
                    print(f"–ü—Ä–æ–ø—É—â–µ–Ω –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª: {json_file.name}")
                    continue

                data['source_file'] = json_file.name
                print(f"–ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {json_file.name}, –∑–∞–ø–∏—Å–µ–π: {len(data)}")
                all_data.append(data)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {json_file}: {e}")
                continue

        if not all_data:
            print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
            return pd.DataFrame()

        combined_data = pd.concat(all_data, ignore_index=True)
        print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(combined_data)}")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ—Ç–∞–ª–∏ –º–æ–¥–µ–ª–µ–π
        combined_data = self._extract_model_details(combined_data)

        return combined_data

    def _extract_model_details(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ—Ç–∞–ª–∏ –º–æ–¥–µ–ª–µ–π –∏–∑ model_details –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∏—Ö –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏.

        Args:
            df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏

        Returns:
            DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ –¥–µ—Ç–∞–ª–µ–π –º–æ–¥–µ–ª–µ–π
        """
        def extract_details(row) -> pd.Series:
            """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ—Ç–∞–ª–∏ –∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
            try:
                details = row.get('model_details', {})
                if isinstance(details, dict):
                    model_details = details.get('details', {})
                    if isinstance(model_details, dict):
                        family = model_details.get('family', 'Unknown')
                        params = model_details.get('parameter_size', 'Unknown')
                        quant = model_details.get('quantization_level', 'Unknown')
                        model_format = model_details.get('format', 'Unknown')

                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞–∑–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
                        params_normalized = self._normalize_parameter_size(params)

                        return pd.Series([
                            family, params, quant, model_format, params_normalized
                        ], index=[
                            'model_family', 'parameter_size', 'quantization_level',
                            'model_format', 'params_group'
                        ])
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–µ—Ç–∞–ª–µ–π –º–æ–¥–µ–ª–∏: {e}")

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            return pd.Series([
                'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown'
            ], index=[
                'model_family', 'parameter_size', 'quantization_level',
                'model_format', 'params_group'
            ])

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π –∫ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–µ
        details_df = df.apply(extract_details, axis=1)
        result_df = pd.concat([df, details_df], axis=1)

        self.model_details_extracted = True
        print("‚úÖ –î–µ—Ç–∞–ª–∏ –º–æ–¥–µ–ª–µ–π —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã")

        return result_df

    def _normalize_parameter_size(self, param_size: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ä–∞–∑–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏.

        Args:
            param_size: –°—Ç—Ä–æ–∫–∞ —Å —Ä–∞–∑–º–µ—Ä–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "7B", "6.9B")

        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≥—Ä—É–ø–ø–∞ —Ä–∞–∑–º–µ—Ä–∞
        """
        if not isinstance(param_size, str) or param_size == 'Unknown':
            return 'Unknown'

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        try:
            # –£–±–∏—Ä–∞–µ–º 'B' –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ float
            size_str = param_size.upper().replace('B', '').strip()
            size_float = float(size_str)

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º
            if size_float <= 1.0:
                return '‚â§1B'
            elif size_float <= 3.0:
                return '1B-3B'
            elif size_float <= 8.0:
                return '3B-8B'
            elif size_float <= 15.0:
                return '8B-15B'
            elif size_float <= 35.0:
                return '15B-35B'
            elif size_float <= 75.0:
                return '35B-75B'
            else:
                return '>75B'
        except (ValueError, TypeError):
            return 'Unknown'

    def generate_comprehensive_report(self) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ –≤—Å–µ–º–∏ —Ç–∏–ø–∞–º–∏ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–æ–≤."""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self.all_results = self._load_all_results()

        if self.all_results.empty:
            return "# üìä –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –û—Ç—á–µ—Ç\n\n–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')

        report_md = f"# üìä –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –û—Ç—á–µ—Ç –æ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ LLM\n\n"
        report_md += f"*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {timestamp}*\n\n"

        # 1. –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        report_md += self._generate_overview_stats()

        # 2. –û—Å–Ω–æ–≤–Ω–æ–π –ª–∏–¥–µ—Ä–±–æ—Ä–¥ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏
        report_md += "\n" + self._generate_accuracy_leaderboard()

        # 3. –°–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–∏–¥–µ—Ä–±–æ—Ä–¥—ã
        report_md += "\n" + self._generate_segmented_leaderboards()

        # 4. –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        report_md += "\n" + self._generate_detailed_stats()

        return report_md

    def _generate_overview_stats(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
        total_models = self.all_results['model_name'].nunique()
        total_tests = len(self.all_results)
        avg_accuracy = self.all_results['is_correct'].mean()

        families = self.all_results['model_family'].value_counts()
        param_groups = self.all_results['params_group'].value_counts()

        stats_md = "## üìà –û–±—â–∞—è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n"
        stats_md += f"- **–í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π:** {total_models}\n"
        stats_md += f"- **–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤:** {total_tests:,}\n"
        stats_md += f"- **–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å:** {avg_accuracy:.1%}\n\n"

        stats_md += "### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–µ–º–µ–π—Å—Ç–≤–∞–º:\n"
        for family, count in families.head(10).items():
            stats_md += f"- **{family}:** {count} —Ç–µ—Å—Ç–æ–≤\n"

        stats_md += "\n### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º:\n"
        for group, count in param_groups.items():
            if group != 'Unknown':
                stats_md += f"- **{group}:** {count} —Ç–µ—Å—Ç–æ–≤\n"

        return stats_md

    def _generate_accuracy_leaderboard(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ª–∏–¥–µ—Ä–±–æ—Ä–¥ —Ç–æ–ª—å–∫–æ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏."""
        metrics = self.all_results.groupby('model_name').agg({
            'is_correct': 'mean',
            'source_file': 'nunique',
            'model_family': 'first',
            'parameter_size': 'first',
            'quantization_level': 'first'
        }).round(4)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏
        metrics.sort_values('is_correct', ascending=False, inplace=True)
        metrics.insert(0, '–†–∞–Ω–≥', range(1, len(metrics) + 1))

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        display_df = metrics.copy()
        display_df['is_correct'] = display_df['is_correct'].map(lambda x: f"{x:.1%}")
        display_df.columns = [
            '–†–∞–Ω–≥', '–¢–æ—á–Ω–æ—Å—Ç—å', '–ó–∞–ø—É—Å–∫–æ–≤', '–°–µ–º–µ–π—Å—Ç–≤–æ', '–ü–∞—Ä–∞–º–µ—Ç—Ä—ã', '–ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è'
        ]
        display_df.index.name = '–ú–æ–¥–µ–ª—å'

        leaderboard_md = "## üéØ –õ–∏–¥–µ—Ä–±–æ—Ä–¥ –ø–æ –¢–æ—á–Ω–æ—Å—Ç–∏\n\n"
        leaderboard_md += "*–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –æ—Ç–≤–µ—Ç–æ–≤*\n\n"
        leaderboard_md += self._to_markdown_table(display_df)

        return leaderboard_md

    def _generate_segmented_leaderboards(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–∏–¥–µ—Ä–±–æ—Ä–¥—ã –ø–æ –≥—Ä—É–ø–ø–∞–º –º–æ–¥–µ–ª–µ–π."""
        segment_md = "## üèÜ –°–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –õ–∏–¥–µ—Ä–±–æ—Ä–¥—ã\n\n"
        segment_md += "*–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞*\n\n"

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏
        segments = self.all_results.groupby(['params_group', 'quantization_level'])

        for (params_group, quant_level), group_df in segments:
            if params_group == 'Unknown' or len(group_df['model_name'].unique()) < 2:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≥—Ä—É–ø–ø—ã —Å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏–ª–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é

            segment_md += f"### üé™ –ö–ª–∞—Å—Å: {params_group} ({quant_level})\n\n"
            segment_md += self._generate_composite_leaderboard_for_group(group_df)
            segment_md += "\n"

        return segment_md

    def _generate_composite_leaderboard_for_group(
            self,
            group_df: pd.DataFrame,
            accuracy_weight: float = 0.7,
            speed_weight: float = 0.3
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π –ª–∏–¥–µ—Ä–±–æ—Ä–¥ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≥—Ä—É–ø–ø—ã –º–æ–¥–µ–ª–µ–π.

        Args:
            group_df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã
            accuracy_weight: –í–µ—Å —Ç–æ—á–Ω–æ—Å—Ç–∏
            speed_weight: –í–µ—Å —Å–∫–æ—Ä–æ—Å—Ç–∏

        Returns:
            Markdown-—Ç–µ–∫—Å—Ç –ª–∏–¥–µ—Ä–±–æ—Ä–¥–∞
        """
        if len(group_df['model_name'].unique()) < 2:
            return "*–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è*\n\n"

        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = group_df.groupby('model_name').agg({
            'is_correct': 'mean',
            'execution_time_ms': 'mean',
            'source_file': 'nunique'
        })

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics['norm_accuracy'] = metrics['is_correct']

        min_time = metrics['execution_time_ms'].min()
        max_time = metrics['execution_time_ms'].max()
        if max_time == min_time:
            metrics['norm_speed'] = 0.5
        else:
            metrics['norm_speed'] = (max_time - metrics['execution_time_ms']) / (max_time - min_time)

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π –±–∞–ª–ª
        metrics['composite_score'] = (
                accuracy_weight * metrics['norm_accuracy'] +
                speed_weight * metrics['norm_speed']
        )

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–º–ø–æ–∑–∏—Ç–Ω–æ–º—É –±–∞–ª–ª—É
        metrics.sort_values('composite_score', ascending=False, inplace=True)
        metrics.insert(0, '–†–∞–Ω–≥', range(1, len(metrics) + 1))

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        display_df = metrics.copy()
        display_df['composite_score'] = display_df['composite_score'].map(lambda x: f"{x:.3f}")
        display_df['is_correct'] = display_df['is_correct'].map(lambda x: f"{x:.1%}")
        display_df['execution_time_ms'] = display_df['execution_time_ms'].map(lambda x: f"{x:,.0f}")

        display_df = display_df[['–†–∞–Ω–≥', 'composite_score', 'is_correct', 'execution_time_ms', 'source_file']]
        display_df.columns = ['–†–∞–Ω–≥', '–ë–∞–ª–ª', '–¢–æ—á–Ω–æ—Å—Ç—å', '–í—Ä–µ–º—è (–º—Å)', '–ó–∞–ø—É—Å–∫–æ–≤']
        display_df.index.name = '–ú–æ–¥–µ–ª—å'

        return self._to_markdown_table(display_df)

    def _generate_detailed_stats(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Ç–µ—Å—Ç–æ–≤."""
        detailed_md = "## üìã –î–µ—Ç–∞–ª—å–Ω–∞—è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n"

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏ –º–æ–¥–µ–ª—è–º
        category_stats = self.all_results.groupby(['model_name', 'category']).agg({
            'is_correct': ['count', 'sum', 'mean'],
            'execution_time_ms': 'mean'
        }).round(2)

        category_stats.columns = ['–í—Å–µ–≥–æ', '–ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö', '–¢–æ—á–Ω–æ—Å—Ç—å', '–í—Ä–µ–º—è_–º—Å']
        category_stats['–¢–æ—á–Ω–æ—Å—Ç—å'] = category_stats['–¢–æ—á–Ω–æ—Å—Ç—å'].map(lambda x: f"{x:.1%}")
        category_stats['–í—Ä–µ–º—è_–º—Å'] = category_stats['–í—Ä–µ–º—è_–º—Å'].map(lambda x: f"{x:,.0f}")

        detailed_md += "### –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Ç–µ—Å—Ç–æ–≤:\n\n"
        detailed_md += self._to_markdown_table(category_stats)

        return detailed_md

    def _to_markdown_table(self, df: pd.DataFrame) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç DataFrame –≤ Markdown —Ç–∞–±–ª–∏—Ü—É."""
        if df.empty:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö\n"

        df_display = df.fillna('N/A')
        lines = []

        if isinstance(df_display.index, pd.MultiIndex):
            headers = list(df_display.index.names) + list(df_display.columns)
        else:
            index_name = df_display.index.name if df_display.index.name else '–≠–ª–µ–º–µ–Ω—Ç'
            headers = [index_name] + list(df_display.columns)

        lines.append("| " + " | ".join(str(h) for h in headers) + " |")
        lines.append("| " + " | ".join(["---"] * len(headers)) + " |")

        for idx, row in df_display.iterrows():
            if isinstance(idx, tuple):
                row_values = [str(i) for i in idx] + [str(v) for v in row.values]
            else:
                row_values = [str(idx)] + [str(v) for v in row.values]
            lines.append("| " + " | ".join(row_values) + " |")

        return "\n".join(lines) + "\n"

    def get_model_recommendations(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–µ–π."""
        if self.all_results.empty:
            return "## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.\n"

        recommendations_md = "## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –í—ã–±–æ—Ä—É –ú–æ–¥–µ–ª–µ–π\n\n"

        # –õ—É—á—à–∞—è –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏
        best_accuracy = self.all_results.groupby('model_name')['is_correct'].mean().idxmax()
        best_acc_value = self.all_results.groupby('model_name')['is_correct'].mean().max()

        # –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è
        fastest_model = self.all_results.groupby('model_name')['execution_time_ms'].mean().idxmin()
        fastest_time = self.all_results.groupby('model_name')['execution_time_ms'].mean().min()

        recommendations_md += f"### üéØ **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å:** {best_accuracy}\n"
        recommendations_md += f"*–¢–æ—á–Ω–æ—Å—Ç—å: {best_acc_value:.1%}*\n\n"

        recommendations_md += f"### ‚ö° **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å:** {fastest_model}\n"
        recommendations_md += f"*–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {fastest_time:,.0f} –º—Å*\n\n"

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–º–µ—Ä–Ω—ã–º –≥—Ä—É–ø–ø–∞–º
        param_groups = self.all_results['params_group'].unique()
        for group in sorted(param_groups):
            if group == 'Unknown':
                continue

            group_data = self.all_results[self.all_results['params_group'] == group]
            if len(group_data['model_name'].unique()) > 1:
                best_in_group = group_data.groupby('model_name')['is_correct'].mean().idxmax()
                best_acc_in_group = group_data.groupby('model_name')['is_correct'].mean().max()

                recommendations_md += f"### üèÖ **–õ—É—á—à–∞—è –≤ –∫–ª–∞—Å—Å–µ {group}:** {best_in_group}\n"
                recommendations_md += f"*–¢–æ—á–Ω–æ—Å—Ç—å: {best_acc_in_group:.1%}*\n\n"

        return recommendations_md

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    reporter = AdvancedReporter(Path("./test_results"))

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
    full_report = reporter.generate_comprehensive_report()

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    full_report += reporter.get_model_recommendations()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    with open("comprehensive_report.md", "w", encoding="utf-8") as f:
        f.write(full_report)

    print("‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ comprehensive_report.md")
