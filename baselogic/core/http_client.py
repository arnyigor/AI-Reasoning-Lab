import requests
import json
import logging
from typing import Dict, Any, Optional

# –ò—Å–ø–æ–ª—å–∑—É–µ–º llm_logger, –∫–∞–∫ –∏ –≤ OllamaClient, –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
# –ï—Å–ª–∏ —É –≤–∞—Å –¥—Ä—É–≥–æ–π –ª–æ–≥–µ—Ä, –∑–∞–º–µ–Ω–∏—Ç–µ –µ–≥–æ
llm_logger = logging.getLogger(__name__)


class OpenAICompatibleClient:
    """
    HTTP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –ª—é–±—ã–º —Å–µ—Ä–≤–µ—Ä–æ–º, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—â–∏–º
    OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç /chat/completions.
    (–Ω–∞–ø—Ä–∏–º–µ—Ä, LM Studio, Jan, vLLM).
    """
    def __init__(self, model_name: str, api_base: str, api_key: Optional[str] = None, model_options: Optional[Dict[str, Any]] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç HTTP-–∫–ª–∏–µ–Ω—Ç.

        Args:
            model_name (str): –ò–º—è –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–æ–µ –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–Ω–æ –≤ —Ç–µ–ª–µ –∑–∞–ø—Ä–æ—Å–∞.
            api_base (str): –ë–∞–∑–æ–≤—ã–π URL —Å–µ—Ä–≤–µ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "http://localhost:1234/v1").
            api_key (Optional[str]): –ù–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –∫–ª—é—á API.
            model_options (Optional[Dict[str, Any]]): –°–ª–æ–≤–∞—Ä—å —Å –æ–ø—Ü–∏—è–º–∏.
        """
        self.model_name = model_name
        self.api_url = f"{api_base.rstrip('/')}/chat/completions"
        self.api_key = api_key
        self.model_options = model_options if model_options else {}

        # –†–∞–∑–±–∏—Ä–∞–µ–º –æ–ø—Ü–∏–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        self.generation_options = self.model_options.get('generation', {})
        self.prompting_options = self.model_options.get('prompting', {})

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        self.system_prompt = self.prompting_options.get('system_prompt')
        llm_logger.info("‚úÖ OpenAICompatibleClient –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è '%s' –ø–æ –∞–¥—Ä–µ—Å—É: %s", model_name, self.api_url)

    def query(self, user_prompt: str) -> str:
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç HTTP POST-–∑–∞–ø—Ä–æ—Å –Ω–∞ —Å–µ—Ä–≤–µ—Ä –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç.
        """
        headers = {
            "Content-Type": "application/json",
        }
        if self.api_key:
            headers["Authorization"] = f"Bearer {self.api_key}"

        messages = []
        if self.system_prompt:
            messages.append({'role': 'system', 'content': self.system_prompt})
        messages.append({'role': 'user', 'content': user_prompt})

        # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–µ–π OpenAI
        payload = {
            "model": self.model_name,
            "messages": messages,
            "stream": False,
            **self.generation_options # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –æ–ø—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: temp, stop, etc.
        }

        # --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ ---
        log_message = (
            f"REQUEST (HTTP):\n"
            f"  URL: {self.api_url}\n"
            f"  Headers: {headers}\n"
            f"  Payload: {json.dumps(payload, indent=2, ensure_ascii=False)}\n\n"
        )
        llm_logger.debug(log_message)

        try:
            timeout = self.model_options.get('query_timeout', 180) # –¢–∞–π–º–∞—É—Ç 3 –º–∏–Ω—É—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            llm_logger.info("    üöÄ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ API (—Ç–∞–π–º–∞—É—Ç: %d—Å)...", timeout)
            response = requests.post(self.api_url, headers=headers, json=payload, timeout=timeout)
            response.raise_for_status()  # –í—ã–∑–æ–≤–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –∫–æ–¥–æ–≤ 4xx/5xx

            data = response.json()

            if not data.get('choices'):
                raise ValueError("–û—Ç–≤–µ—Ç API –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á 'choices'")

            full_response_text = data['choices'][0]['message']['content']

            log_message += f"RESPONSE (Success):\n{full_response_text}"
            llm_logger.info("    ‚úÖ –û—Ç–≤–µ—Ç –æ—Ç API –ø–æ–ª—É—á–µ–Ω.")
            llm_logger.debug(log_message)
            return full_response_text.strip()

        except requests.exceptions.Timeout:
            error_details = "RESPONSE (HTTP Timeout Error): –°–µ—Ä–≤–µ—Ä –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –∑–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è."
            llm_logger.error(error_details)
            return f"TIMEOUT_ERROR: {error_details}"
        except requests.exceptions.RequestException as e:
            error_details = f"RESPONSE (HTTP Request Error):\n{e}"
            log_message += error_details
            llm_logger.error(log_message, exc_info=True)
            return f"HTTP_ERROR: {e}"
        except (ValueError, KeyError, IndexError) as e:
            raw_response = response.text if 'response' in locals() else "No response received"
            error_details = f"RESPONSE (JSON Parsing Error):\n{e}\nRaw Response: {raw_response}"
            log_message += error_details
            llm_logger.error(log_message, exc_info=True)
            return f"JSON_PARSING_ERROR: {e}"

    # =========================================================================
    # –î–û–ë–ê–í–õ–ï–ù–û: –ú–µ—Ç–æ–¥-–∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å TestRunner
    # =========================================================================
    def get_model_details(self) -> Dict[str, Any]:
        """
        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç "–∑–∞–≥–ª—É—à–∫—É" —Å –¥–µ—Ç–∞–ª—è–º–∏ –¥–ª—è API-–º–æ–¥–µ–ª–µ–π.
        –≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å –ø—Ä–æ—Ü–µ—Å—Å–æ–º —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤ TestRunner.
        """
        llm_logger.info("    ‚öôÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π –¥–ª—è API-–º–æ–¥–µ–ª–∏: %s", self.model_name)
        # OpenAI API –Ω–µ –∏–º–µ—é—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ 'show', –∫–∞–∫ —É Ollama.
        # –ú—ã –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —á—Ç–æ–±—ã Reporter –º–æ–≥ –µ–µ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å.
        return {
            "modelfile": "N/A (API)",
            "parameters": "N/A (API)",
            "template": self.prompting_options.get('template', 'N/A (API)'),
            "details": {
                "family": "api",  # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
                "parameter_size": "N/A",
                "quantization_level": "API",
                "format": "api"
            },
            # –≠—Ç–æ—Ç —Ñ–ª–∞–≥ –ø–æ–º–æ–∂–µ—Ç Reporter'—É —Ç–æ—á–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —á—Ç–æ —ç—Ç–æ API –º–æ–¥–µ–ª—å
            "object": "model"
        }

